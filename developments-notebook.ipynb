{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Interactive Development Environment - Algoritmo GD Project\n",
      "======================================================================\n",
      "2025-06-12 17:08:58,385 |     INFO | Logger initialized for algoritmo_GD\n",
      "‚úÖ Project modules imported successfully\n",
      "üìÅ Project: algoritmo_GD\n",
      "üóÇÔ∏è  Root directory: c:\\ALCAMPO\\python-algorithms\\algortimo-gd\n",
      "2025-06-12 17:08:58,789 |     INFO | Logger initialized for algoritmo_GD\n",
      "\n",
      "üìã Setting up configuration and external data...\n",
      "üìä Data source: CSV files\n",
      "üìÖ Date range: 2025-01-01 to 2025-12-31\n",
      "üî¢ Process ID: 249652\n",
      "\n",
      "üîß Initializing data manager and components...\n",
      "2025-06-12 17:08:58,791 |     INFO | Logger initialized for base_data_project\n",
      "2025-06-12 17:08:58,792 |     INFO | Data manager for 'db' not registered, trying built-in managers\n",
      "2025-06-12 17:08:58,793 |     INFO | Initialized BaseDataManager\n",
      "‚úÖ Data manager created successfully\n",
      "\n",
      "üìä Loading project data into memory...\n",
      "2025-06-12 17:08:58,794 |     INFO | Initialized DescansosDataModel\n",
      "2025-06-12 17:08:58,796 |     INFO | DataContainer initialized\n",
      "‚úÖ Data model initialized\n",
      "2025-06-12 17:08:58,830 |     INFO | Connected to database: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "\n",
      "üîÑ Stage 1: Loading process data...\n",
      "2025-06-12 17:08:58,832 |     INFO | Loading process data from data manager\n",
      "2025-06-12 17:08:58,833 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-12 17:08:58,836 |     INFO | Replaced {process_id} with '249652'\n",
      "2025-06-12 17:08:58,837 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-12 17:08:58,838 |     INFO | Loading database data for entity 'valid_emp'\n",
      "2025-06-12 17:08:58,838 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:00,720 |     INFO | Successfully loaded 1 rows using custom query\n",
      "2025-06-12 17:09:00,722 |     INFO | valid_emp: Index(['codigo', 'fk_aviso', 'fk_unidade', 'fk_secao', 'fk_perfil', 'fk_cargo',\n",
      "       'fk_aviso_clube', 'fk_colaborador'],\n",
      "      dtype='object')\n",
      "2025-06-12 17:09:00,741 |     INFO | Date counts per year: {'2025': np.int64(365)}\n",
      "2025-06-12 17:09:00,743 |     INFO | Year with most dates is: 2025\n",
      "2025-06-12 17:09:00,745 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-12 17:09:00,749 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-12 17:09:00,751 |     INFO | Loading database data for entity 'params_lq'\n",
      "2025-06-12 17:09:00,752 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:00,879 |     INFO | Successfully loaded 5 rows using custom query\n",
      "2025-06-12 17:09:00,881 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-12 17:09:00,884 |     INFO | Replaced {unit_id} with '02897'\n",
      "2025-06-12 17:09:00,886 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-12 17:09:00,888 |     INFO | Loading database data for entity 'df_festivos'\n",
      "2025-06-12 17:09:00,889 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:01,018 |     INFO | Successfully loaded 14 rows using custom query\n",
      "2025-06-12 17:09:01,021 |     INFO | Successfully loaded 3 entities\n",
      "‚úÖ Process data loaded successfully\n",
      "   üìã Valid employees: 1 records\n",
      "   üè¢ Unit ID: 02897\n",
      "   üè≠ Section ID: 9552\n",
      "   üë§ Position IDs: [684]\n",
      "\n",
      "üîÑ Stage 2: Loading detailed data for positions...\n",
      "üìç Processing position ID: 684\n",
      "2025-06-12 17:09:01,024 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-12 17:09:01,027 |     INFO | Replaced {colabs_id} with 36891\n",
      "2025-06-12 17:09:01,029 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-12 17:09:01,033 |     INFO | Loading database data for entity 'df_colaborador'\n",
      "2025-06-12 17:09:01,035 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:01,133 |     INFO | Successfully loaded 1 rows using custom query\n",
      "   ‚úÖ Colaborador info loaded\n",
      "      üìä 1 employee records\n",
      "2025-06-12 17:09:01,138 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-12 17:09:01,141 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-12 17:09:01,142 |     INFO | Loading database data for entity 'df_estrutura_wfm'\n",
      "2025-06-12 17:09:01,144 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:03,020 |     INFO | Successfully loaded 2777 rows using custom query\n",
      "2025-06-12 17:09:03,021 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-12 17:09:03,024 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-12 17:09:03,025 |     INFO | Loading database data for entity 'df_feriados'\n",
      "2025-06-12 17:09:03,026 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:04,248 |     INFO | Successfully loaded 1743 rows using custom query\n",
      "2025-06-12 17:09:04,249 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-12 17:09:04,251 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-12 17:09:04,253 |     INFO | Loading database data for entity 'df_faixa_horario'\n",
      "2025-06-12 17:09:04,256 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:05,591 |     INFO | Successfully loaded 1862 rows using custom query\n",
      "2025-06-12 17:09:05,592 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-12 17:09:05,595 |     INFO | Replaced {posto_id} with 684\n",
      "2025-06-12 17:09:05,595 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-12 17:09:05,596 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-12 17:09:05,598 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-12 17:09:05,599 |     INFO | Loading database data for entity 'df_orcamento'\n",
      "2025-06-12 17:09:05,600 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:21,120 |     INFO | Successfully loaded 21900 rows using custom query\n",
      "2025-06-12 17:09:21,124 |     INFO | df_orcamento columns: ['fk_unidade', 'unidade', 'fk_secao', 'secao', 'fk_tipo_posto', 'tipo_posto', 'percentual_posto', 'fc', 'data', 'hora_ini', 'itens', 'valor', 'tipo']\n",
      "2025-06-12 17:09:21,124 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-12 17:09:21,126 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-12 17:09:21,126 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-12 17:09:21,127 |     INFO | Replaced {posto_id} with 684\n",
      "2025-06-12 17:09:21,127 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-12 17:09:21,128 |     INFO | Loading database data for entity 'df_granularidade'\n",
      "2025-06-12 17:09:21,129 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:35,132 |     INFO | Successfully loaded 21287 rows using custom query\n",
      "   ‚úÖ Estimativas info loaded\n",
      "      üìà 0 estimate records\n",
      "2025-06-12 17:09:35,141 |     INFO | df_colaborador shape: (1, 47)\n",
      "2025-06-12 17:09:35,142 |     INFO | df_colaborador columns: ['fk_colaborador', 'loja', 'secao', 'puesto', 'convenio', 'nome', 'emp', 'min_dias_trabalhados', 'max_dias_trabalhados', 'tipo_de_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'lq', 'q', 'fds_cal_2d', 'fds_cal_3d', 'd_cal_xx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde']\n",
      "2025-06-12 17:09:35,144 |     INFO | Found 0 employees with 90-day cycles\n",
      "2025-06-12 17:09:35,145 |     INFO | first_date_passado: 2025-01-01\n",
      "2025-06-12 17:09:35,146 |     INFO | last_date_passado: 2026-01-07\n",
      "2025-06-12 17:09:35,150 |     INFO | Found 0 employees with past admission dates\n",
      "2025-06-12 17:09:35,151 |     INFO | No historical calendar data for employees: []\n",
      "2025-06-12 17:09:35,153 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-12 17:09:35,154 |     INFO | Replaced {colabs_id} with '5039619'\n",
      "2025-06-12 17:09:35,155 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-12 17:09:35,155 |     INFO | Loading database data for entity 'df_ausencias_ferias'\n",
      "2025-06-12 17:09:35,156 |     INFO | Executing custom query\n",
      "2025-06-12 17:09:35,224 |     INFO | Successfully loaded 0 rows using custom query\n",
      "2025-06-12 17:09:35,226 |     INFO | No employees with 90-day cycles\n",
      "2025-06-12 17:09:35,228 |     INFO | load_calendario_info completed successfully\n",
      "   ‚úÖ Calendario info loaded\n",
      "      üìÖ Calendar matrix: (0, 0)\n",
      "\n",
      "üîÑ Stage 3: Performing data transformations...\n",
      "2025-06-12 17:09:35,259 |     INFO | df_feriados_filtered columns: ['fk_unidade', 'fk_pais', 'fk_estado', 'fk_cidade', 'database', 'descricao', 'tipo', 'feriado_fixo']\n",
      "   ‚úÖ Estimativas transformations completed\n",
      "2025-06-12 17:09:39,656 |     INFO | Starting load_ma_bd processing\n",
      "2025-06-12 17:09:39,680 |    ERROR | Empleado 5039619 sin suficiente LQ para fines de semana de calidad\n",
      "2025-06-12 17:09:39,681 |     INFO | columnes matriz a: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato']\n",
      "2025-06-12 17:09:39,682 |     INFO | load_ma_bd completed successfully. Processed 1 employees.\n",
      "   ‚úÖ Colaborador transformations completed\n",
      "2025-06-12 17:09:39,683 |     INFO | Starting load_m2_bd processing\n",
      "2025-06-12 17:09:39,684 |     INFO | DEBUG: start_date=2025-01-01, end_date=2025-12-31\n",
      "2025-06-12 17:09:39,685 |     INFO | DEBUG: matriz_ma shape=(1, 54)\n",
      "2025-06-12 17:09:39,686 |     INFO | DEBUG: all_colab_pad length=1\n",
      "2025-06-12 17:09:39,689 |     INFO | DEBUG: date_range length=365\n",
      "2025-06-12 17:09:39,691 |     INFO | DEBUG: dia_row length=731, turno_row length=731\n",
      "2025-06-12 17:09:39,714 |     INFO | DEBUG: After headers, matrix shape=(3, 731)\n",
      "2025-06-12 17:09:39,724 |     INFO | DEBUG: Final matrix shape=(4, 731)\n",
      "2025-06-12 17:09:39,725 |     INFO | DEBUG: Successfully stored df_calendario\n",
      "   ‚úÖ Calendario transformations completed\n",
      "2025-06-12 17:09:39,726 |     INFO | matriz2_og shape: (4, 731)\n",
      "2025-06-12 17:09:39,734 |     INFO | matriz2_og first few rows:\n",
      "          0           1           2           3           4           5    \\\n",
      "0         Dia  2025-01-01  2025-01-01  2025-01-02  2025-01-02  2025-01-03   \n",
      "1       TURNO           M           T           M           T           M   \n",
      "2    TIPO_DIA           -           -           -           -           -   \n",
      "3  0005039619           -           -           -           -           -   \n",
      "\n",
      "          6           7           8           9    ...         721  \\\n",
      "0  2025-01-03  2025-01-04  2025-01-04  2025-01-05  ...  2025-12-27   \n",
      "1           T           M           T           M  ...           M   \n",
      "2           -           -           -           -  ...           -   \n",
      "3           -           -           -           -  ...           -   \n",
      "\n",
      "          722         723         724         725         726         727  \\\n",
      "0  2025-12-27  2025-12-28  2025-12-28  2025-12-29  2025-12-29  2025-12-30   \n",
      "1           T           M           T           M           T           M   \n",
      "2           -           -           -           -           -           -   \n",
      "3           -           -           -           -           -           -   \n",
      "\n",
      "          728         729         730  \n",
      "0  2025-12-30  2025-12-31  2025-12-31  \n",
      "1           T           M           T  \n",
      "2           -           -           -  \n",
      "3           -           -           -  \n",
      "\n",
      "[4 rows x 731 columns]\n",
      "2025-06-12 17:09:39,735 |     INFO | matriz2_og first column unique values: ['Dia' 'TURNO' 'TIPO_DIA' '0005039619']\n",
      "2025-06-12 17:09:39,736 |     INFO | TURNO row exists: True\n",
      "2025-06-12 17:09:39,736 |     INFO | Dia row exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:864: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  output_final = output_final.fillna(0)\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1062: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matriz_ma[non_date_columns] = matriz_ma[non_date_columns].fillna(0)\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1379: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1380: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 17:09:39,932 |     INFO | Columns in matrizA_og after processing: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato', 'ld', 'l_dom', 'lq_og', 'total_dom_fes', 'total_fes', 'total_holidays', 'descansos_atrb', 'COLABORADOR', 'LD_at', 'LQ_at', 'LRES_at', 'CXX_at', 'C2D_at', 'C3D_at']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1785: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matrizA_og = matrizA_og.merge(count_ldt, left_on='matricula', right_on='COLABORADOR', how='left').fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 17:09:40,809 |     INFO | func_inicializa MatrizB creation completed successfully\n",
      "2025-06-12 17:09:40,810 |     INFO | func_inicializa completed successfully\n",
      "   ‚úÖ func_inicializa completed\n",
      "2025-06-12 17:09:40,938 |     INFO | Closed database session\n",
      "2025-06-12 17:09:41,083 |     INFO | Disposed database engine\n",
      "\n",
      "üéâ Data loading completed!\n",
      "\n",
      "üìä Organizing DataFrames for interactive access...\n",
      "\n",
      "üìã AVAILABLE DATAFRAMES\n",
      "======================================================================\n",
      "\n",
      "üóÇÔ∏è AUXILIARY:\n",
      "   üìã messages_df               ‚Üí      0 rows √ó   0 columns\n",
      "   üìã params_lq                 ‚Üí      5 rows √ó   2 columns\n",
      "   üìã valid_emp                 ‚Üí      1 rows √ó   8 columns\n",
      "   üìã colabs_id_list            ‚Üí      1 rows √ó   0 columns\n",
      "   üìã df_festivos               ‚Üí     14 rows √ó   2 columns\n",
      "   üìã df_turnos                 ‚Üí      2 rows √ó   6 columns\n",
      "   üìã df_calendario_passado     ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_count                  ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_estrutura_wfm          ‚Üí   2777 rows √ó   6 columns\n",
      "   üìã df_feriados               ‚Üí   1743 rows √ó   8 columns\n",
      "   üìã df_faixa_horario          ‚Üí   1862 rows √ó  19 columns\n",
      "   üìã df_orcamento              ‚Üí  21900 rows √ó  13 columns\n",
      "   üìã df_granularidade          ‚Üí  21287 rows √ó  11 columns\n",
      "   üìã df_calendario_past        ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_ausencias_ferias       ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_ciclos_90              ‚Üí      0 rows √ó   0 columns\n",
      "\n",
      "üìÅ RAW:\n",
      "   üìã df_calendario             ‚Üí      4 rows √ó 731 columns\n",
      "   üìã df_colaborador            ‚Üí      1 rows √ó  54 columns\n",
      "   üìã df_estimativas            ‚Üí    730 rows √ó   8 columns\n",
      "\n",
      "‚öôÔ∏è MEDIUM (Transformed):\n",
      "   üìã df_calendario             ‚Üí   1456 rows √ó  12 columns\n",
      "   üìã df_colaborador            ‚Üí      1 rows √ó  22 columns\n",
      "   üìã df_estimativas            ‚Üí      0 rows √ó  13 columns\n",
      "   üìã matrizA_bk_og             ‚Üí      1 rows √ó  21 columns\n",
      "   üìã matriz_data_turno_bk      ‚Üí      1 rows √ó   1 columns\n",
      "\n",
      "üíé RARE (Algorithm Results): (no DataFrames yet)\n",
      "\n",
      "üìä FORMATTED (Final): (no DataFrames yet)\n",
      "\n",
      "üîó QUICK ACCESS VARIABLES\n",
      "======================================================================\n",
      "‚úÖ valid_emp           ‚Üí (1, 8)\n",
      "‚úÖ df_colaborador      ‚Üí (1, 54)\n",
      "‚úÖ df_estimativas      ‚Üí (730, 8)\n",
      "‚úÖ df_calendario       ‚Üí (4, 731)\n",
      "\n",
      "üõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\n",
      "======================================================================\n",
      "üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\n",
      "üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\n",
      "üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\n",
      "üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\n",
      "üìä df_info()                                  ‚Üí Show all DataFrames info\n",
      "\n",
      "üí° EXAMPLE USAGE:\n",
      "======================================================================\n",
      "# Explore specific DataFrames\n",
      "explore_df(valid_emp, 'Valid Employees')\n",
      "explore_df(df_colaborador, 'Employee Details')\n",
      "\n",
      "# Compare DataFrames\n",
      "compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\n",
      "\n",
      "# Show sample data\n",
      "show_sample_data(raw_dataframes, 'Raw Data', 3)\n",
      "\n",
      "# Search for specific columns\n",
      "search_columns('matricula')\n",
      "search_columns('data')\n",
      "\n",
      "# Access DataFrames directly\n",
      "valid_emp.head()\n",
      "df_colaborador.describe()\n",
      "matrizA_bk.columns\n",
      "\n",
      "üéØ DIRECT ACCESS TO PROJECT DATA:\n",
      "======================================================================\n",
      "üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\n",
      "üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\n",
      "‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\n",
      "üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\n",
      "üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\n",
      "\n",
      "üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\n",
      "üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\n",
      "‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\n",
      "\n",
      "‚ú® READY FOR INTERACTIVE DEVELOPMENT!\n",
      "üîß All project DataFrames are loaded and available in memory\n",
      "üìù Use the utility functions above to explore and analyze the data\n",
      "üöÄ Start developing your data transformations!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Development Notebook - Algoritmo GD Project\n",
    "# Load real project data and keep DataFrames in memory for development\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "# Add project root to path so we can import from src/\n",
    "project_root = Path.cwd()\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"üöÄ Interactive Development Environment - Algoritmo GD Project\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. IMPORT PROJECT MODULES AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Import project configuration and modules\n",
    "    from src.config import CONFIG, PROJECT_NAME\n",
    "    from src.models import DescansosDataModel\n",
    "    from base_data_project.utils import create_components\n",
    "    from base_data_project.log_config import setup_logger\n",
    "    \n",
    "    print(\"‚úÖ Project modules imported successfully\")\n",
    "    print(f\"üìÅ Project: {PROJECT_NAME}\")\n",
    "    print(f\"üóÇÔ∏è  Root directory: {project_root}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing project modules: {e}\")\n",
    "    print(\"Make sure you're running this notebook from the project root directory\")\n",
    "    raise\n",
    "\n",
    "# Configure logging\n",
    "logger = setup_logger(PROJECT_NAME, log_level=logging.INFO)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CONFIGURATION AND EXTERNAL DATA SETUP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã Setting up configuration and external data...\")\n",
    "\n",
    "# Use the real project configuration\n",
    "use_db = False  # Set to True if you want to use database, False for CSV\n",
    "external_call_data = CONFIG.get('external_call_data', {\n",
    "    'current_process_id': 249652,\n",
    "    'api_proc_id': 999,\n",
    "    'wfm_proc_id': 249652,\n",
    "    'wfm_user': 'WFM',\n",
    "    'start_date': '2025-01-01',\n",
    "    'end_date': '2025-12-31',\n",
    "    'wfm_proc_colab': None,\n",
    "})\n",
    "\n",
    "print(f\"üìä Data source: {'Database' if use_db else 'CSV files'}\")\n",
    "print(f\"üìÖ Date range: {external_call_data['start_date']} to {external_call_data['end_date']}\")\n",
    "print(f\"üî¢ Process ID: {external_call_data['current_process_id']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. INITIALIZE DATA MANAGER AND COMPONENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîß Initializing data manager and components...\")\n",
    "\n",
    "try:\n",
    "    # Create data manager using the project's utility function\n",
    "    data_manager, process_manager = create_components(\n",
    "        use_db=use_db, \n",
    "        no_tracking=True,  # Disable tracking for development\n",
    "        config=CONFIG,\n",
    "        project_name=PROJECT_NAME  # Pass project name explicitly\n",
    "    )\n",
    "    print(\"‚úÖ Data manager created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating data manager: {e}\")\n",
    "    raise\n",
    "\n",
    "# =============================================================================\n",
    "# 4. LOAD PROJECT DATA INTO MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Loading project data into memory...\")\n",
    "\n",
    "# Initialize the data model with real project structure\n",
    "data_model = DescansosDataModel(\n",
    "    project_name=PROJECT_NAME, \n",
    "    external_data=external_call_data\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data model initialized\")\n",
    "\n",
    "# Context manager for data manager connection\n",
    "with data_manager:\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.1 LOAD PROCESS DATA (Stage 1)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 1: Loading process data...\")\n",
    "    \n",
    "    try:\n",
    "        # Get entities to load from configuration\n",
    "        entities_dict = CONFIG.get('available_entities_processing', {})\n",
    "        \n",
    "        success = data_model.load_process_data(data_manager, entities_dict)\n",
    "        \n",
    "        if success:\n",
    "            print(\"‚úÖ Process data loaded successfully\")\n",
    "            print(f\"   üìã Valid employees: {len(data_model.auxiliary_data.get('valid_emp', []))} records\")\n",
    "            print(f\"   üè¢ Unit ID: {data_model.auxiliary_data.get('unit_id')}\")\n",
    "            print(f\"   üè≠ Section ID: {data_model.auxiliary_data.get('secao_id')}\")\n",
    "            print(f\"   üë§ Position IDs: {data_model.auxiliary_data.get('posto_id_list')}\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load process data\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Stage 1: {e}\")\n",
    "        logger.error(f\"Stage 1 error: {e}\", exc_info=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.2 LOAD DETAILED DATA FOR EACH POSITION (Stage 2)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 2: Loading detailed data for positions...\")\n",
    "    \n",
    "    posto_id_list = data_model.auxiliary_data.get('posto_id_list', [])\n",
    "    \n",
    "    if posto_id_list:\n",
    "        # Process first position as example (you can modify this)\n",
    "        posto_id = posto_id_list[0]\n",
    "        print(f\"üìç Processing position ID: {posto_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load colaborador info\n",
    "            success = data_model.load_colaborador_info(data_manager, posto_id)\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Colaborador info loaded\")\n",
    "                df_colaborador = data_model.raw_data.get('df_colaborador')\n",
    "                if df_colaborador is not None:\n",
    "                    print(f\"      üìä {len(df_colaborador)} employee records\")\n",
    "            \n",
    "            # Load estimativas info  \n",
    "            success = data_model.load_estimativas_info(\n",
    "                data_manager, \n",
    "                posto_id, \n",
    "                external_call_data['start_date'], \n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Estimativas info loaded\")\n",
    "                df_estimativas = data_model.raw_data.get('df_estimativas')\n",
    "                if df_estimativas is not None:\n",
    "                    print(f\"      üìà {len(df_estimativas)} estimate records\")\n",
    "            \n",
    "            # Load calendario info\n",
    "            success = data_model.load_calendario_info(\n",
    "                data_manager,\n",
    "                external_call_data['current_process_id'],\n",
    "                posto_id,\n",
    "                external_call_data['start_date'],\n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Calendario info loaded\")\n",
    "                df_calendario = data_model.raw_data.get('df_calendario')\n",
    "                if df_calendario is not None:\n",
    "                    print(f\"      üìÖ Calendar matrix: {df_calendario.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error loading data for position {posto_id}: {e}\")\n",
    "            logger.error(f\"Position {posto_id} error: {e}\", exc_info=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.3 PERFORM DATA TRANSFORMATIONS (Stage 3)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 3: Performing data transformations...\")\n",
    "    \n",
    "    try:\n",
    "        # Load estimativas transformations\n",
    "        success = data_model.load_estimativas_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Estimativas transformations completed\")\n",
    "        \n",
    "        # Load colaborador transformations  \n",
    "        success = data_model.load_colaborador_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Colaborador transformations completed\")\n",
    "        \n",
    "        # Load calendario transformations\n",
    "        success = data_model.load_calendario_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Calendario transformations completed\")\n",
    "        \n",
    "        # Perform func_inicializa\n",
    "        success = data_model.func_inicializa(\n",
    "            start_date=external_call_data['start_date'],\n",
    "            end_date=external_call_data['end_date'],\n",
    "            fer=data_model.auxiliary_data.get('df_festivos'),\n",
    "            closed_days=data_model.auxiliary_data.get('df_closed_days')\n",
    "        )\n",
    "        if success:\n",
    "            print(\"   ‚úÖ func_inicializa completed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ORGANIZE DATAFRAMES FOR EASY ACCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Organizing DataFrames for interactive access...\")\n",
    "\n",
    "# Extract all DataFrames from the data model\n",
    "auxiliary_dataframes = {}\n",
    "raw_dataframes = {}\n",
    "medium_dataframes = {}\n",
    "rare_dataframes = {}\n",
    "formatted_dataframes = {}\n",
    "\n",
    "# Auxiliary data\n",
    "for key, value in data_model.auxiliary_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        auxiliary_dataframes[key] = value\n",
    "\n",
    "# Raw data  \n",
    "for key, value in data_model.raw_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        raw_dataframes[key] = value\n",
    "\n",
    "# Medium data (transformed)\n",
    "for key, value in data_model.medium_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        medium_dataframes[key] = value\n",
    "\n",
    "# Rare data (algorithm results)\n",
    "for key, value in data_model.rare_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        rare_dataframes[key] = value\n",
    "\n",
    "# Formatted data (final output)\n",
    "for key, value in data_model.formatted_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        formatted_dataframes[key] = value\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DISPLAY AVAILABLE DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã AVAILABLE DATAFRAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_dataframes = {\n",
    "    \"üóÇÔ∏è AUXILIARY\": auxiliary_dataframes,\n",
    "    \"üìÅ RAW\": raw_dataframes, \n",
    "    \"‚öôÔ∏è MEDIUM (Transformed)\": medium_dataframes,\n",
    "    \"üíé RARE (Algorithm Results)\": rare_dataframes,\n",
    "    \"üìä FORMATTED (Final)\": formatted_dataframes\n",
    "}\n",
    "\n",
    "for category, dataframes in all_dataframes.items():\n",
    "    if dataframes:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: (no DataFrames yet)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. QUICK ACCESS VARIABLES AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîó QUICK ACCESS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make key DataFrames easily accessible with simple variable names\n",
    "try:\n",
    "    if 'valid_emp' in auxiliary_dataframes:\n",
    "        valid_emp = auxiliary_dataframes['valid_emp']\n",
    "        print(f\"‚úÖ valid_emp           ‚Üí {valid_emp.shape}\")\n",
    "    \n",
    "    if 'df_colaborador' in raw_dataframes:\n",
    "        df_colaborador = raw_dataframes['df_colaborador']\n",
    "        print(f\"‚úÖ df_colaborador      ‚Üí {df_colaborador.shape}\")\n",
    "    \n",
    "    if 'df_estimativas' in raw_dataframes:\n",
    "        df_estimativas = raw_dataframes['df_estimativas']\n",
    "        print(f\"‚úÖ df_estimativas      ‚Üí {df_estimativas.shape}\")\n",
    "    \n",
    "    if 'df_calendario' in raw_dataframes:\n",
    "        df_calendario = raw_dataframes['df_calendario']\n",
    "        print(f\"‚úÖ df_calendario       ‚Üí {df_calendario.shape}\")\n",
    "    \n",
    "    if 'matrizA_bk' in medium_dataframes:\n",
    "        matrizA_bk = medium_dataframes['matrizA_bk']\n",
    "        print(f\"‚úÖ matrizA_bk          ‚Üí {matrizA_bk.shape}\")\n",
    "    \n",
    "    if 'matriz2_bk' in medium_dataframes:\n",
    "        matriz2_bk = medium_dataframes['matriz2_bk']\n",
    "        print(f\"‚úÖ matriz2_bk          ‚Üí {matriz2_bk.shape}\")\n",
    "    \n",
    "    if 'matrizB_bk' in medium_dataframes:\n",
    "        matrizB_bk = medium_dataframes['matrizB_bk']\n",
    "        print(f\"‚úÖ matrizB_bk          ‚Üí {matrizB_bk.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some DataFrames may not be available yet: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. UTILITY FUNCTIONS FOR DATA EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def explore_df(df, name=\"DataFrame\"):\n",
    "    \"\"\"Explore a DataFrame with detailed information\"\"\"\n",
    "    print(f\"\\nüîç EXPLORING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nüìã Columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        print(f\"   {i+1:2d}. {col:<20} ({dtype}) - {null_count} nulls\")\n",
    "    \n",
    "    print(f\"\\nüìä First 3 rows:\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_dfs(*dataframes, names=None):\n",
    "    \"\"\"Compare multiple DataFrames\"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"DataFrame_{i+1}\" for i in range(len(dataframes))]\n",
    "    \n",
    "    print(f\"\\nüîÑ COMPARING DATAFRAMES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in zip(names, dataframes):\n",
    "        print(f\"üìã {name:<20} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    \n",
    "    # Check for common columns\n",
    "    if len(dataframes) > 1:\n",
    "        all_columns = [set(df.columns) for df in dataframes]\n",
    "        common_cols = set.intersection(*all_columns)\n",
    "        \n",
    "        print(f\"\\nüîó Common columns ({len(common_cols)}):\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "def show_sample_data(df_dict, category_name, n_rows=3):\n",
    "    \"\"\"Show sample data from DataFrames in a category\"\"\"\n",
    "    print(f\"\\nüìñ SAMPLE DATA: {category_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"\\nüîπ {name} (showing {min(n_rows, len(df))} rows):\")\n",
    "        if len(df) > 0:\n",
    "            print(df.head(n_rows).to_string())\n",
    "        else:\n",
    "            print(\"   (empty DataFrame)\")\n",
    "\n",
    "def search_columns(pattern, df_dict=None):\n",
    "    \"\"\"Search for columns matching a pattern across all DataFrames\"\"\"\n",
    "    if df_dict is None:\n",
    "        df_dict = {**auxiliary_dataframes, **raw_dataframes, **medium_dataframes}\n",
    "    \n",
    "    print(f\"\\nüîç SEARCHING COLUMNS: '{pattern}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found = False\n",
    "    for df_name, df in df_dict.items():\n",
    "        matching_cols = [col for col in df.columns if pattern.lower() in col.lower()]\n",
    "        if matching_cols:\n",
    "            found = True\n",
    "            print(f\"\\nüìã {df_name}:\")\n",
    "            for col in matching_cols:\n",
    "                print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"‚ùå No columns found matching '{pattern}'\")\n",
    "\n",
    "def df_info():\n",
    "    \"\"\"Show information about all available DataFrames\"\"\"\n",
    "    print(f\"\\nüìä ALL DATAFRAMES INFO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    categories = [\n",
    "        (\"üóÇÔ∏è AUXILIARY\", auxiliary_dataframes),\n",
    "        (\"üìÅ RAW\", raw_dataframes),\n",
    "        (\"‚öôÔ∏è MEDIUM\", medium_dataframes),\n",
    "        (\"üíé RARE\", rare_dataframes),\n",
    "        (\"üìä FORMATTED\", formatted_dataframes)\n",
    "    ]\n",
    "    \n",
    "    for category_name, df_dict in categories:\n",
    "        if df_dict:\n",
    "            print(f\"\\n{category_name}:\")\n",
    "            for name, df in df_dict.items():\n",
    "                memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "                print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} cols ({memory_mb:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. INSTRUCTIONS AND EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\")\n",
    "print(\"üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\")  \n",
    "print(\"üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\")\n",
    "print(\"üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\")\n",
    "print(\"üìä df_info()                                  ‚Üí Show all DataFrames info\")\n",
    "\n",
    "print(f\"\\nüí° EXAMPLE USAGE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"# Explore specific DataFrames\")\n",
    "print(\"explore_df(valid_emp, 'Valid Employees')\")\n",
    "print(\"explore_df(df_colaborador, 'Employee Details')\")\n",
    "print(\"\")\n",
    "print(\"# Compare DataFrames\")\n",
    "print(\"compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\")\n",
    "print(\"\")\n",
    "print(\"# Show sample data\")\n",
    "print(\"show_sample_data(raw_dataframes, 'Raw Data', 3)\")\n",
    "print(\"\")\n",
    "print(\"# Search for specific columns\")\n",
    "print(\"search_columns('matricula')\")\n",
    "print(\"search_columns('data')\")\n",
    "print(\"\")\n",
    "print(\"# Access DataFrames directly\")\n",
    "print(\"valid_emp.head()\")\n",
    "print(\"df_colaborador.describe()\")\n",
    "print(\"matrizA_bk.columns\")\n",
    "\n",
    "print(f\"\\nüéØ DIRECT ACCESS TO PROJECT DATA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\")\n",
    "print(\"üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\")  \n",
    "print(\"‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\")\n",
    "print(\"üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\")\n",
    "print(\"üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\")\n",
    "print(\"\")\n",
    "print(\"üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\")\n",
    "print(\"üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\")\n",
    "print(\"‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\")\n",
    "\n",
    "print(f\"\\n‚ú® READY FOR INTERACTIVE DEVELOPMENT!\")\n",
    "print(\"üîß All project DataFrames are loaded and available in memory\")\n",
    "print(\"üìù Use the utility functions above to explore and analyze the data\")\n",
    "print(\"üöÄ Start developing your data transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f985a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUGGING func_inicializa MatrizB Processing\n",
      "============================================================\n",
      "üìä Starting data:\n",
      "   matrizB_og (df_estimativas): (730, 8)\n",
      "   matriz2_bk: (0, 0)\n",
      "\n",
      "üìã matrizB_og columns: ['data', 'media_turno', 'max_turno', 'min_turno', 'sd_turno', 'turno', 'fk_tipo_posto', 'data_turno']\n",
      "üìä matrizB_og sample:\n",
      "        data  media_turno  max_turno  min_turno  sd_turno turno fk_tipo_posto  \\\n",
      "0 2025-01-01          0.0        0.0        0.0       0.0     m          None   \n",
      "1 2025-01-02          0.0        0.0        0.0       0.0     m          None   \n",
      "2 2025-01-03          0.0        0.0        0.0       0.0     m          None   \n",
      "\n",
      "     data_turno  \n",
      "0  2025-01-01_m  \n",
      "1  2025-01-02_m  \n",
      "2  2025-01-03_m  \n",
      "\n",
      "üìÖ Year from data: 2025\n",
      "‚úÖ Applied special date adjustments\n",
      "   matrizB_ini shape after adjustments: (730, 8)\n",
      "\n",
      "üîÑ Creating +H column from matriz2_bk...\n",
      "‚ùå matriz2_bk is empty - cannot create +H column!\n",
      "\n",
      "üß™ TESTING MatrizB Transformation\n",
      "==================================================\n",
      "üìä Starting with: (730, 8)\n",
      "   ‚úÖ Converted max_turno to numeric\n",
      "   ‚úÖ Converted min_turno to numeric\n",
      "   ‚úÖ Converted media_turno to numeric\n",
      "   ‚úÖ Converted sd_turno to numeric\n",
      "   ‚úÖ Added +H column\n",
      "   ‚úÖ Applied calculations\n",
      "   üìä Final shape: (730, 12)\n",
      "   ‚úÖ Test successful - stored in medium_data['test_df_estimativas']\n",
      "\n",
      "‚úÖ The transformation CAN work!\n",
      "   The issue is likely in the +H calculation logic in func_inicializa\n",
      "   Check the matriz2_bk processing section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antonio.alves\\AppData\\Local\\Temp\\ipykernel_10708\\152442828.py:48: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
      "C:\\Users\\antonio.alves\\AppData\\Local\\Temp\\ipykernel_10708\\152442828.py:49: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n"
     ]
    }
   ],
   "source": [
    "# Debug func_inicializa MatrizB Processing\n",
    "# This focuses on the specific part where df_estimativas gets processed\n",
    "\n",
    "def debug_func_inicializa_matrizb(data_model):\n",
    "    \"\"\"\n",
    "    Debug the MatrizB processing in func_inicializa where df_estimativas is handled\n",
    "    \"\"\"\n",
    "    print(\"üîç DEBUGGING func_inicializa MatrizB Processing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get the starting data\n",
    "    matrizB_og = data_model.raw_data.get('df_estimativas', pd.DataFrame()).copy()\n",
    "    matriz2_bk = data_model.medium_data.get('matriz2_bk', pd.DataFrame())\n",
    "    \n",
    "    print(f\"üìä Starting data:\")\n",
    "    print(f\"   matrizB_og (df_estimativas): {matrizB_og.shape}\")\n",
    "    print(f\"   matriz2_bk: {matriz2_bk.shape}\")\n",
    "    \n",
    "    if len(matrizB_og) == 0:\n",
    "        print(\"‚ùå matrizB_og is empty - this is the source of the problem!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìã matrizB_og columns: {list(matrizB_og.columns)}\")\n",
    "    print(f\"üìä matrizB_og sample:\")\n",
    "    print(matrizB_og.head(3))\n",
    "    \n",
    "    # Get year from matrizB_og\n",
    "    if 'data' in matrizB_og.columns:\n",
    "        ano = pd.to_datetime(matrizB_og['data'].min()).year\n",
    "        print(f\"\\nüìÖ Year from data: {ano}\")\n",
    "        \n",
    "        # Adjust minTurno for specific dates (this is from the R code)\n",
    "        special_dates = [f'{ano}-12-23', f'{ano}-12-24', f'{ano}-12-30', f'{ano}-12-31']\n",
    "        friday_dates = [f'{ano}-12-22', f'{ano}-12-29']\n",
    "        \n",
    "        matrizB_ini = matrizB_og.copy()\n",
    "        \n",
    "        # Check if the required columns exist\n",
    "        required_cols = ['min_turno', 'max_turno']\n",
    "        missing_cols = [col for col in required_cols if col not in matrizB_ini.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "            print(f\"   Available columns: {list(matrizB_ini.columns)}\")\n",
    "            return\n",
    "        \n",
    "        # Apply the special date logic\n",
    "        matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
    "        mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n",
    "        matrizB_ini.loc[mask_friday, 'min_turno'] = matrizB_ini.loc[mask_friday, 'max_turno']\n",
    "        \n",
    "        print(f\"‚úÖ Applied special date adjustments\")\n",
    "        print(f\"   matrizB_ini shape after adjustments: {matrizB_ini.shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå 'data' column not found in matrizB_og\")\n",
    "        return\n",
    "    \n",
    "    # Now the critical part - creating the +H column\n",
    "    print(f\"\\nüîÑ Creating +H column from matriz2_bk...\")\n",
    "    \n",
    "    if len(matriz2_bk) == 0:\n",
    "        print(\"‚ùå matriz2_bk is empty - cannot create +H column!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìã matriz2_bk columns: {list(matriz2_bk.columns)}\")\n",
    "    \n",
    "    # Check the logic for calculating +H for morning shifts\n",
    "    print(f\"\\nüåÖ Processing morning shifts...\")\n",
    "    \n",
    "    trab_manha_data = []\n",
    "    unique_dates = matriz2_bk['DATA'].unique() if 'DATA' in matriz2_bk.columns else []\n",
    "    \n",
    "    print(f\"   Found {len(unique_dates)} unique dates in matriz2_bk\")\n",
    "    \n",
    "    if len(unique_dates) == 0:\n",
    "        print(\"‚ùå No dates found in matriz2_bk DATA column\")\n",
    "        return\n",
    "    \n",
    "    # Sample a few dates to check the logic\n",
    "    sample_dates = unique_dates[:3] if len(unique_dates) >= 3 else unique_dates\n",
    "    \n",
    "    for date in sample_dates:\n",
    "        if date == 'TIPO_DIA':\n",
    "            continue\n",
    "            \n",
    "        day_data = matriz2_bk[(matriz2_bk['DATA'] == date) & \n",
    "                            (matriz2_bk['COLABORADOR'] != 'TIPO_DIA')].copy()\n",
    "        \n",
    "        print(f\"   üìÖ Date {date}: {len(day_data)} employee records\")\n",
    "        \n",
    "        if len(day_data) == 0:\n",
    "            print(f\"      ‚ö†Ô∏è No employee data for date {date}\")\n",
    "            continue\n",
    "        \n",
    "        # Check the TIPO_TURNO and HORARIO columns\n",
    "        if 'TIPO_TURNO' in day_data.columns and 'HORARIO' in day_data.columns:\n",
    "            morning_workers = day_data[\n",
    "                (day_data['TIPO_TURNO'] == 'M') & \n",
    "                (day_data['HORARIO'].str.contains('H|NL', case=False, na=False))\n",
    "            ]\n",
    "            print(f\"      üåÖ Morning workers: {len(morning_workers)}\")\n",
    "        else:\n",
    "            print(f\"      ‚ùå Missing TIPO_TURNO or HORARIO columns\")\n",
    "    \n",
    "    # The issue might be in the merge logic\n",
    "    print(f\"\\nüîó Checking merge logic...\")\n",
    "    \n",
    "    # Check if matrizB_ini has the expected columns for merging\n",
    "    merge_cols = ['data', 'turno']\n",
    "    available_merge_cols = [col for col in merge_cols if col in matrizB_ini.columns]\n",
    "    \n",
    "    print(f\"   Required merge columns: {merge_cols}\")\n",
    "    print(f\"   Available in matrizB_ini: {available_merge_cols}\")\n",
    "    \n",
    "    if len(available_merge_cols) != len(merge_cols):\n",
    "        print(f\"‚ùå Cannot merge - missing columns in matrizB_ini\")\n",
    "        return\n",
    "    \n",
    "    # Test the merge for morning data\n",
    "    if len(trab_manha_data) == 0:\n",
    "        # Create at least one sample to test\n",
    "        trab_manha_data = [{\n",
    "            'DATA': sample_dates[0] if len(sample_dates) > 0 else '2025-01-01',\n",
    "            'TURNO': 'M',\n",
    "            '+H': 5.0\n",
    "        }]\n",
    "    \n",
    "    trab_manha = pd.DataFrame(trab_manha_data)\n",
    "    print(f\"   trab_manha sample: {trab_manha.shape}\")\n",
    "    print(f\"   trab_manha columns: {list(trab_manha.columns)}\")\n",
    "    \n",
    "    # Test merge\n",
    "    matrizB_m = matrizB_ini[matrizB_ini['turno'] == 'M'].copy()\n",
    "    print(f\"   matrizB morning records: {len(matrizB_m)}\")\n",
    "    \n",
    "    if len(matrizB_m) > 0:\n",
    "        try:\n",
    "            merged = matrizB_m.merge(trab_manha, left_on=['data', 'turno'], \n",
    "                                   right_on=['DATA', 'TURNO'], how='left')\n",
    "            print(f\"   ‚úÖ Merge successful: {merged.shape}\")\n",
    "            print(f\"   +H column created: {'+H' in merged.columns}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Merge failed: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìã SUMMARY:\")\n",
    "    print(f\"   üî∏ matrizB_og (input): {matrizB_og.shape}\")\n",
    "    print(f\"   üî∏ Expected output should have +H column\")\n",
    "    print(f\"   üî∏ Issue likely in +H calculation or merge logic\")\n",
    "    \n",
    "    return matrizB_ini\n",
    "\n",
    "# Function to test the exact transformation\n",
    "def test_matrizb_transformation(data_model):\n",
    "    \"\"\"\n",
    "    Test the exact MatrizB transformation to see where it fails\n",
    "    \"\"\"\n",
    "    print(\"\\nüß™ TESTING MatrizB Transformation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get the raw data\n",
    "    matrizB_og = data_model.raw_data.get('df_estimativas', pd.DataFrame()).copy()\n",
    "    \n",
    "    if len(matrizB_og) == 0:\n",
    "        print(\"‚ùå Cannot test - matrizB_og is empty\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Starting with: {matrizB_og.shape}\")\n",
    "    \n",
    "    # Apply the basic transformation steps\n",
    "    try:\n",
    "        # Step 1: Convert data types\n",
    "        numeric_cols = ['max_turno', 'min_turno', 'media_turno', 'sd_turno']\n",
    "        for col in numeric_cols:\n",
    "            if col in matrizB_og.columns:\n",
    "                matrizB_og[col] = pd.to_numeric(matrizB_og[col], errors='coerce')\n",
    "                print(f\"   ‚úÖ Converted {col} to numeric\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Column {col} not found\")\n",
    "        \n",
    "        # Step 2: Add +H column (placeholder)\n",
    "        matrizB_og['+H'] = 0\n",
    "        print(f\"   ‚úÖ Added +H column\")\n",
    "        \n",
    "        # Step 3: Apply the calculation logic\n",
    "        param_pess_obj = 0.5\n",
    "        matrizB_og['aux'] = np.where(\n",
    "            matrizB_og['media_turno'] != 0,\n",
    "            matrizB_og['sd_turno'] / matrizB_og['media_turno'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        matrizB_og['pess_obj'] = np.where(\n",
    "            matrizB_og['aux'] >= param_pess_obj,\n",
    "            np.ceil(matrizB_og['media_turno']),\n",
    "            np.round(matrizB_og['media_turno'])\n",
    "        )\n",
    "        \n",
    "        matrizB_og['diff'] = matrizB_og['+H'] - matrizB_og['pess_obj']\n",
    "        \n",
    "        print(f\"   ‚úÖ Applied calculations\")\n",
    "        print(f\"   üìä Final shape: {matrizB_og.shape}\")\n",
    "        \n",
    "        # Store in medium_data to test\n",
    "        data_model.medium_data['test_df_estimativas'] = matrizB_og.copy()\n",
    "        \n",
    "        print(f\"   ‚úÖ Test successful - stored in medium_data['test_df_estimativas']\")\n",
    "        \n",
    "        return matrizB_og\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the debugging\n",
    "if 'data_model' in locals():\n",
    "    result = debug_func_inicializa_matrizb(data_model)\n",
    "    test_result = test_matrizb_transformation(data_model)\n",
    "    \n",
    "    if test_result is not None:\n",
    "        print(f\"\\n‚úÖ The transformation CAN work!\")\n",
    "        print(f\"   The issue is likely in the +H calculation logic in func_inicializa\")\n",
    "        print(f\"   Check the matriz2_bk processing section\")\n",
    "else:\n",
    "    print(\"‚ùå data_model not found. Run the main notebook first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
