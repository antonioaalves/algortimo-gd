{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Interactive Development Environment - Algoritmo GD Project\n",
      "======================================================================\n",
      "2025-06-25 16:30:07,968 |     INFO | Logger initialized for algoritmo_GD\n",
      "‚úÖ Project modules imported successfully\n",
      "üìÅ Project: algoritmo_GD\n",
      "üóÇÔ∏è  Root directory: c:\\ALCAMPO\\python-algorithms\\algortimo-gd\n",
      "\n",
      "üìã Setting up configuration and external data...\n",
      "üìä Data source: Database\n",
      "üìÖ Date range: 2025-01-01 to 2025-12-31\n",
      "üî¢ Process ID: 249730\n",
      "\n",
      "üîß Initializing data manager and components...\n",
      "Creating components for project: algoritmo_GD\n",
      "2025-06-25 16:30:08,750 |     INFO | Data manager for 'db' not registered, trying built-in managers\n",
      "2025-06-25 16:30:08,752 |     INFO | Initialized BaseDataManager\n",
      "‚úÖ Data manager created successfully\n",
      "\n",
      "üìä Loading project data into memory...\n",
      "2025-06-25 16:30:08,753 |     INFO | Initialized DBDataContainer\n",
      "2025-06-25 16:30:08,754 |     INFO | Initializing database data container with URL: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "2025-06-25 16:30:10,862 |     INFO | Database initialized successfully\n",
      "2025-06-25 16:30:10,863 |     INFO | Initialized DescansosDataModel with project algoritmo_GD\n",
      "2025-06-25 16:30:10,867 |     INFO | DescansosDataModel initialized\n",
      "‚úÖ Data model initialized\n",
      "2025-06-25 16:30:10,869 |     INFO | Connected to database: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "\n",
      "üîÑ Stage 1: Loading process data...\n",
      "2025-06-25 16:30:10,869 |     INFO | Loading process data from data manager\n",
      "2025-06-25 16:30:10,870 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-25 16:30:10,871 |     INFO | Replaced {process_id} with '249730'\n",
      "2025-06-25 16:30:10,967 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-25 16:30:10,968 |     INFO | Loading database data for entity 'valid_emp'\n",
      "2025-06-25 16:30:10,969 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:12,182 |     INFO | Successfully loaded 14 rows using custom query\n",
      "2025-06-25 16:30:12,183 |     INFO | valid_emp: Index(['codigo', 'fk_aviso', 'fk_unidade', 'fk_secao', 'fk_perfil', 'fk_cargo',\n",
      "       'fk_aviso_clube', 'fk_colaborador'],\n",
      "      dtype='object')\n",
      "2025-06-25 16:30:12,185 |     INFO | unit_id: 01015, secao_id: 10150184, posto_id_list: [3386, 153]\n",
      "2025-06-25 16:30:12,190 |     INFO | Date counts per year: {'2025': np.int64(365)}\n",
      "2025-06-25 16:30:12,196 |     INFO | Year with most dates is: 2025\n",
      "2025-06-25 16:30:12,198 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-25 16:30:12,199 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-25 16:30:12,201 |     INFO | Loading database data for entity 'params_lq'\n",
      "2025-06-25 16:30:12,201 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:12,298 |     INFO | Successfully loaded 5 rows using custom query\n",
      "2025-06-25 16:30:12,299 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-25 16:30:12,300 |     INFO | Replaced {unit_id} with '01015'\n",
      "2025-06-25 16:30:12,301 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-25 16:30:12,301 |     INFO | Loading database data for entity 'df_festivos'\n",
      "2025-06-25 16:30:12,302 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:12,402 |     INFO | Successfully loaded 14 rows using custom query\n",
      "2025-06-25 16:30:12,404 |     INFO | Successfully loaded 3 entities\n",
      "‚úÖ Process data loaded successfully\n",
      "   üìã Valid employees: 14 records\n",
      "   üè¢ Unit ID: 01015\n",
      "   üè≠ Section ID: 10150184\n",
      "   üë§ Position IDs: [3386, 153]\n",
      "\n",
      "üîÑ Stage 2: Loading detailed data for positions...\n",
      "üìç Processing position ID: 153\n",
      "2025-06-25 16:30:12,417 |     INFO | colabs_str: 1382,1376,1380,34896,25607,1386,23958,1383,1377,1379,24678,1381,25152\n",
      "2025-06-25 16:30:12,418 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-25 16:30:12,421 |     INFO | Replaced {colabs_id} with 1382,1376,1380,34896,25607,1386,23958,1383,1377,1379,24678,1381,25152\n",
      "2025-06-25 16:30:12,426 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-25 16:30:12,432 |     INFO | Loading database data for entity 'df_colaborador'\n",
      "2025-06-25 16:30:12,434 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:12,547 |     INFO | Successfully loaded 13 rows using custom query\n",
      "   ‚úÖ Colaborador info loaded\n",
      "      üìä 13 employee records\n",
      "2025-06-25 16:30:12,550 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-25 16:30:12,552 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-25 16:30:12,553 |     INFO | Loading database data for entity 'df_estrutura_wfm'\n",
      "2025-06-25 16:30:12,554 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:14,052 |     INFO | Successfully loaded 2777 rows using custom query\n",
      "2025-06-25 16:30:14,053 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-25 16:30:14,054 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-25 16:30:14,055 |     INFO | Loading database data for entity 'df_feriados'\n",
      "2025-06-25 16:30:14,056 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:15,104 |     INFO | Successfully loaded 1743 rows using custom query\n",
      "2025-06-25 16:30:15,106 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-25 16:30:15,114 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-25 16:30:15,116 |     INFO | Loading database data for entity 'df_faixa_horario'\n",
      "2025-06-25 16:30:15,117 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:16,196 |     INFO | Successfully loaded 1862 rows using custom query\n",
      "2025-06-25 16:30:16,198 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-25 16:30:16,200 |     INFO | Replaced {posto_id} with 153\n",
      "2025-06-25 16:30:16,200 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-25 16:30:16,201 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-25 16:30:16,202 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-25 16:30:16,203 |     INFO | Loading database data for entity 'df_orcamento'\n",
      "2025-06-25 16:30:16,204 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:28,600 |     INFO | Successfully loaded 23725 rows using custom query\n",
      "2025-06-25 16:30:28,603 |     INFO | df_orcamento columns: ['fk_unidade', 'unidade', 'fk_secao', 'secao', 'fk_tipo_posto', 'tipo_posto', 'data', 'hora_ini', 'pessoas_estimado', 'pessoas_min', 'pessoas_final']\n",
      "2025-06-25 16:30:28,604 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-25 16:30:28,607 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-25 16:30:28,611 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-25 16:30:28,614 |     INFO | Replaced {posto_id} with 153\n",
      "2025-06-25 16:30:28,615 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-25 16:30:28,616 |     INFO | Loading database data for entity 'df_granularidade'\n",
      "2025-06-25 16:30:28,619 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:40,995 |     INFO | Successfully loaded 23725 rows using custom query\n",
      "   ‚úÖ Estimativas info loaded\n",
      "      üìà 0 estimate records\n",
      "2025-06-25 16:30:41,018 |     INFO | df_colaborador shape: (13, 47)\n",
      "2025-06-25 16:30:41,020 |     INFO | df_colaborador columns: ['fk_colaborador', 'loja', 'secao', 'puesto', 'convenio', 'nome', 'emp', 'min_dias_trabalhados', 'max_dias_trabalhados', 'tipo_de_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'lq', 'q', 'fds_cal_2d', 'fds_cal_3d', 'd_cal_xx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde']\n",
      "2025-06-25 16:30:41,022 |     INFO | Found 0 employees with 90-day cycles\n",
      "2025-06-25 16:30:41,027 |     INFO | first_date_passado: 2025-01-01\n",
      "2025-06-25 16:30:41,031 |     INFO | last_date_passado: 2026-01-07\n",
      "2025-06-25 16:30:41,034 |     INFO | Found 10 employees with past admission dates\n",
      "2025-06-25 16:30:41,036 |     INFO | No historical calendar data for employees: [1386, 24678, 1382, 1380, 1379, 1377, 23958, 1383, 1381, 1376]\n",
      "2025-06-25 16:30:41,037 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-25 16:30:41,040 |     INFO | Replaced {colabs_id} with '5016794','5037932','5038542','5003281','0155613','0155612','5038307','0155550','5036116','5006519','0375558','0155540','5039237'\n",
      "2025-06-25 16:30:41,045 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-25 16:30:41,048 |     INFO | Loading database data for entity 'df_ausencias_ferias'\n",
      "2025-06-25 16:30:41,049 |     INFO | Executing custom query\n",
      "2025-06-25 16:30:41,565 |     INFO | Successfully loaded 803 rows using custom query\n",
      "2025-06-25 16:30:41,566 |     INFO | No employees with 90-day cycles\n",
      "2025-06-25 16:30:41,567 |     INFO | load_calendario_info completed successfully\n",
      "   ‚úÖ Calendario info loaded\n",
      "      üìÖ Calendar matrix: (0, 0)\n",
      "2025-06-25 16:30:41,662 |     INFO | Closed database session\n",
      "2025-06-25 16:30:41,764 |     INFO | Disposed database engine\n"
     ]
    }
   ],
   "source": [
    "# Interactive Development Notebook - Algoritmo GD Project\n",
    "# Load real project data and keep DataFrames in memory for development\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "# Add project root to path so we can import from src/\n",
    "project_root = Path.cwd()\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"üöÄ Interactive Development Environment - Algoritmo GD Project\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. IMPORT PROJECT MODULES AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Import project configuration and modules\n",
    "    from src.config import CONFIG, PROJECT_NAME\n",
    "    from src.models import DescansosDataModel\n",
    "    from base_data_project.utils import create_components\n",
    "    from base_data_project.log_config import setup_logger\n",
    "    from base_data_project.storage.containers import CSVDataContainer, DBDataContainer\n",
    "    \n",
    "    print(\"‚úÖ Project modules imported successfully\")\n",
    "    print(f\"üìÅ Project: {PROJECT_NAME}\")\n",
    "    print(f\"üóÇÔ∏è  Root directory: {project_root}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing project modules: {e}\")\n",
    "    print(\"Make sure you're running this notebook from the project root directory\")\n",
    "    raise\n",
    "\n",
    "# Configure logging\n",
    "logger = setup_logger(PROJECT_NAME, log_level=logging.INFO)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CONFIGURATION AND EXTERNAL DATA SETUP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã Setting up configuration and external data...\")\n",
    "\n",
    "# Use the real project configuration\n",
    "use_db = True  # Set to True if you want to use database, False for CSV\n",
    "external_call_data = CONFIG.get('external_call_data', {\n",
    "    'current_process_id': 249652,\n",
    "    'api_proc_id': 999,\n",
    "    'wfm_proc_id': 249652,\n",
    "    'wfm_user': 'WFM',\n",
    "    'start_date': '2025-01-01',\n",
    "    'end_date': '2025-12-31',\n",
    "    'wfm_proc_colab': None,\n",
    "})\n",
    "\n",
    "print(f\"üìä Data source: {'Database' if use_db else 'CSV files'}\")\n",
    "print(f\"üìÖ Date range: {external_call_data['start_date']} to {external_call_data['end_date']}\")\n",
    "print(f\"üî¢ Process ID: {external_call_data['current_process_id']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. INITIALIZE DATA MANAGER AND COMPONENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîß Initializing data manager and components...\")\n",
    "\n",
    "try:\n",
    "    # Create data manager using the project's utility function\n",
    "    data_manager, process_manager = create_components(\n",
    "        use_db=use_db, \n",
    "        no_tracking=True,  # Disable tracking for development\n",
    "        config=CONFIG,\n",
    "        project_name=PROJECT_NAME  # Pass project name explicitly\n",
    "    )\n",
    "    print(\"‚úÖ Data manager created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating data manager: {e}\")\n",
    "    raise\n",
    "\n",
    "# =============================================================================\n",
    "# 4. LOAD PROJECT DATA INTO MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Loading project data into memory...\")\n",
    "\n",
    "# Create the appropriate data container based on configuration\n",
    "if use_db:\n",
    "    data_container = DBDataContainer(\n",
    "        project_name=PROJECT_NAME,\n",
    "        config=CONFIG\n",
    "    )\n",
    "else:\n",
    "    data_container = CSVDataContainer(\n",
    "        project_name=PROJECT_NAME,\n",
    "        config=CONFIG\n",
    "    )\n",
    "\n",
    "# Initialize the data model with real project structure and data container\n",
    "data_model = DescansosDataModel(\n",
    "    project_name=PROJECT_NAME, \n",
    "    external_data=external_call_data,\n",
    "    data_container=data_container\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data model initialized\")\n",
    "\n",
    "# Context manager for data manager connection\n",
    "with data_manager:\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.1 LOAD PROCESS DATA (Stage 1)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 1: Loading process data...\")\n",
    "    \n",
    "    try:\n",
    "        # Get entities to load from configuration\n",
    "        entities_dict = CONFIG.get('available_entities_processing', {})\n",
    "        \n",
    "        success = data_model.load_process_data(data_manager, entities_dict)\n",
    "        \n",
    "        if success:\n",
    "            print(\"‚úÖ Process data loaded successfully\")\n",
    "            print(f\"   üìã Valid employees: {len(data_model.auxiliary_data.get('valid_emp', []))} records\")\n",
    "            print(f\"   üè¢ Unit ID: {data_model.auxiliary_data.get('unit_id')}\")\n",
    "            print(f\"   üè≠ Section ID: {data_model.auxiliary_data.get('secao_id')}\")\n",
    "            print(f\"   üë§ Position IDs: {data_model.auxiliary_data.get('posto_id_list')}\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load process data\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Stage 1: {e}\")\n",
    "        logger.error(f\"Stage 1 error: {e}\", exc_info=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.2 LOAD DETAILED DATA FOR EACH POSITION (Stage 2)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 2: Loading detailed data for positions...\")\n",
    "    \n",
    "    posto_id_list = data_model.auxiliary_data.get('posto_id_list', [])\n",
    "\n",
    "    \n",
    "    if posto_id_list:\n",
    "        # Process first position as example (you can modify this)\n",
    "        posto_id = posto_id_list[1]\n",
    "        print(f\"üìç Processing position ID: {posto_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load colaborador info\n",
    "            success = data_model.load_colaborador_info(data_manager, posto_id)\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Colaborador info loaded\")\n",
    "                df_colaborador = data_model.raw_data.get('df_colaborador')\n",
    "                if df_colaborador is not None:\n",
    "                    print(f\"      üìä {len(df_colaborador)} employee records\")\n",
    "            \n",
    "            # Load estimativas info  \n",
    "            success = data_model.load_estimativas_info(\n",
    "                data_manager, \n",
    "                posto_id, \n",
    "                external_call_data['start_date'], \n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Estimativas info loaded\")\n",
    "                df_estimativas = data_model.raw_data.get('df_estimativas')\n",
    "                if df_estimativas is not None:\n",
    "                    print(f\"      üìà {len(df_estimativas)} estimate records\")\n",
    "            \n",
    "            # Load calendario info\n",
    "            success = data_model.load_calendario_info(\n",
    "                data_manager,\n",
    "                external_call_data['current_process_id'],\n",
    "                posto_id,\n",
    "                external_call_data['start_date'],\n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Calendario info loaded\")\n",
    "                df_calendario = data_model.raw_data.get('df_calendario')\n",
    "                if df_calendario is not None:\n",
    "                    print(f\"      üìÖ Calendar matrix: {df_calendario.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error loading data for position {posto_id}: {e}\")\n",
    "            logger.error(f\"Position {posto_id} error: {e}\", exc_info=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c83c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:30:57,602 |     INFO | Connected to database: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "\n",
      "üîÑ Stage 3: Performing data transformations...\n",
      "--------------------------------\n",
      "Pre-tratamento\n",
      "df_granularidade:       fk_unidade     unidade  fk_secao               secao  fk_tipo_posto  \\\n",
      "0          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "1          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "2          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "3          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "4          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "...          ...         ...       ...                 ...            ...   \n",
      "23720      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23721      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23722      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23723      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23724      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "\n",
      "      tipo_posto       data            hora_ini  pessoas_estimado  \\\n",
      "0       VENTA PF 2025-01-01 2000-01-01 06:00:00                 0   \n",
      "1       VENTA PF 2025-01-01 2000-01-01 06:15:00                 0   \n",
      "2       VENTA PF 2025-01-01 2000-01-01 06:30:00                 0   \n",
      "3       VENTA PF 2025-01-01 2000-01-01 06:45:00                 0   \n",
      "4       VENTA PF 2025-01-01 2000-01-01 07:00:00                 0   \n",
      "...          ...        ...                 ...               ...   \n",
      "23720   VENTA PF 2025-03-11 2000-01-01 17:00:00                 1   \n",
      "23721   VENTA PF 2025-03-11 2000-01-01 17:15:00                 1   \n",
      "23722   VENTA PF 2025-03-11 2000-01-01 17:30:00                 1   \n",
      "23723   VENTA PF 2025-03-11 2000-01-01 17:45:00                 1   \n",
      "23724   VENTA PF 2025-03-11 2000-01-01 18:00:00                 2   \n",
      "\n",
      "       pessoas_min  pessoas_final  \n",
      "0                0              0  \n",
      "1                0              0  \n",
      "2                0              0  \n",
      "3                0              0  \n",
      "4                3              3  \n",
      "...            ...            ...  \n",
      "23720            2              2  \n",
      "23721            2              2  \n",
      "23722            2              2  \n",
      "23723            2              2  \n",
      "23724            2              2  \n",
      "\n",
      "[23725 rows x 11 columns]\n",
      "df_faixa_horario:       fk_secao            aber_seg            fech_seg            aber_ter  \\\n",
      "0            1 2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "1            2 2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "2     29220311 2000-01-01 07:00:00 2000-01-01 22:15:00 2000-01-01 07:00:00   \n",
      "3     29220181 2000-01-01 07:00:00 2000-01-01 22:15:00 2000-01-01 07:00:00   \n",
      "4     29220169 2000-01-01 06:30:00 2000-01-01 15:00:00 2000-01-01 06:30:00   \n",
      "...        ...                 ...                 ...                 ...   \n",
      "1857     16850 2000-01-01 06:00:00 2000-01-01 21:30:00 2000-01-01 06:00:00   \n",
      "1858     16850 2000-01-01 06:00:00 2000-01-01 22:30:00 2000-01-01 06:00:00   \n",
      "1859     16864 2000-01-01 05:00:00 2000-01-01 13:30:00 2000-01-01 05:00:00   \n",
      "1860     17714 2000-01-01 09:00:00 2000-01-01 21:00:00 2000-01-01 09:00:00   \n",
      "1861     17091 2000-01-01 08:00:00 2000-01-01 22:30:00 2000-01-01 08:00:00   \n",
      "\n",
      "                fech_ter            aber_qua            fech_qua  \\\n",
      "0    2000-01-01 18:00:00 2000-01-01 09:00:00 2000-01-01 18:00:00   \n",
      "1    2000-01-01 18:00:00 2000-01-01 09:00:00 2000-01-01 18:00:00   \n",
      "2    2000-01-01 22:15:00 2000-01-01 07:00:00 2000-01-01 22:15:00   \n",
      "3    2000-01-01 22:15:00 2000-01-01 07:00:00 2000-01-01 22:15:00   \n",
      "4    2000-01-01 15:00:00 2000-01-01 06:30:00 2000-01-01 15:00:00   \n",
      "...                  ...                 ...                 ...   \n",
      "1857 2000-01-01 21:30:00 2000-01-01 06:00:00 2000-01-01 21:30:00   \n",
      "1858 2000-01-01 22:30:00 2000-01-01 06:00:00 2000-01-01 22:30:00   \n",
      "1859 2000-01-01 13:30:00 2000-01-01 05:00:00 2000-01-01 13:30:00   \n",
      "1860 2000-01-01 21:00:00 2000-01-01 09:00:00 2000-01-01 21:00:00   \n",
      "1861 2000-01-01 22:30:00 2000-01-01 08:00:00 2000-01-01 22:30:00   \n",
      "\n",
      "                aber_qui            fech_qui            aber_sex  \\\n",
      "0    2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "1    2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "2    2000-01-01 07:00:00 2000-01-01 22:15:00 2000-01-01 07:00:00   \n",
      "3    2000-01-01 07:00:00 2000-01-01 22:15:00 2000-01-01 07:00:00   \n",
      "4    2000-01-01 06:30:00 2000-01-01 15:00:00 2000-01-01 06:30:00   \n",
      "...                  ...                 ...                 ...   \n",
      "1857 2000-01-01 06:00:00 2000-01-01 21:30:00 2000-01-01 06:00:00   \n",
      "1858 2000-01-01 06:00:00 2000-01-01 22:30:00 2000-01-01 06:00:00   \n",
      "1859 2000-01-01 05:00:00 2000-01-01 13:30:00 2000-01-01 05:00:00   \n",
      "1860 2000-01-01 09:00:00 2000-01-01 21:00:00 2000-01-01 09:00:00   \n",
      "1861 2000-01-01 08:00:00 2000-01-01 22:30:00 2000-01-01 08:00:00   \n",
      "\n",
      "                fech_sex            aber_sab            fech_sab  \\\n",
      "0    2000-01-01 18:00:00 2000-01-01 09:00:00 2000-01-01 18:00:00   \n",
      "1    2000-01-01 18:00:00 2000-01-01 09:00:00 2000-01-01 18:00:00   \n",
      "2    2000-01-01 22:15:00 2000-01-01 07:00:00 2000-01-01 22:15:00   \n",
      "3    2000-01-01 22:15:00 2000-01-01 07:00:00 2000-01-01 22:15:00   \n",
      "4    2000-01-01 15:00:00 2000-01-01 06:30:00 2000-01-01 15:00:00   \n",
      "...                  ...                 ...                 ...   \n",
      "1857 2000-01-01 21:30:00 2000-01-01 06:00:00 2000-01-01 21:30:00   \n",
      "1858 2000-01-01 22:30:00 2000-01-01 06:00:00 2000-01-01 22:30:00   \n",
      "1859 2000-01-01 13:30:00 2000-01-01 05:00:00 2000-01-01 13:30:00   \n",
      "1860 2000-01-01 21:00:00 2000-01-01 09:00:00 2000-01-01 21:00:00   \n",
      "1861 2000-01-01 22:30:00 2000-01-01 08:00:00 2000-01-01 22:30:00   \n",
      "\n",
      "                aber_dom            fech_dom            aber_fer  \\\n",
      "0    2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "1    2000-01-01 09:00:00 2000-01-01 18:00:00 2000-01-01 09:00:00   \n",
      "2    2000-01-01 08:30:00 2000-01-01 21:15:00 2000-01-01 08:30:00   \n",
      "3    2000-01-01 08:30:00 2000-01-01 21:15:00 2000-01-01 08:30:00   \n",
      "4    2000-01-01 08:30:00 2000-01-01 16:00:00 2000-01-01 08:30:00   \n",
      "...                  ...                 ...                 ...   \n",
      "1857 2000-01-01 06:00:00 2000-01-01 21:30:00 2000-01-01 06:00:00   \n",
      "1858 2000-01-01 06:00:00 2000-01-01 22:30:00 2000-01-01 06:00:00   \n",
      "1859 2000-01-01 05:00:00 2000-01-01 13:30:00 2000-01-01 05:00:00   \n",
      "1860 2000-01-01 09:00:00 2000-01-01 21:00:00 2000-01-01 09:00:00   \n",
      "1861 2000-01-01 08:00:00 2000-01-01 22:30:00 2000-01-01 08:00:00   \n",
      "\n",
      "                fech_fer   data_ini   data_fim  \n",
      "0    2000-01-01 18:00:00 2019-01-07 2049-12-26  \n",
      "1    2000-01-01 18:00:00 2019-01-07 2049-12-26  \n",
      "2    2000-01-01 21:15:00 2023-12-31 2049-04-25  \n",
      "3    2000-01-01 21:15:00 2023-12-31 2049-04-25  \n",
      "4    2000-01-01 16:00:00 2023-12-25 2049-04-25  \n",
      "...                  ...        ...        ...  \n",
      "1857 2000-01-01 21:30:00 2024-12-30 2025-06-01  \n",
      "1858 2000-01-01 22:30:00 2025-06-02 2025-09-28  \n",
      "1859 2000-01-01 13:30:00 2024-12-30 2049-04-25  \n",
      "1860 2000-01-01 21:00:00 2024-01-01 2049-04-25  \n",
      "1861 2000-01-01 22:30:00 2024-01-01 2049-04-25  \n",
      "\n",
      "[1862 rows x 19 columns]\n",
      "df_feriados:      fk_unidade fk_pais fk_estado fk_cidade    database          descricao  \\\n",
      "0         02922    None      None      None  2024-03-28            festivo   \n",
      "1         02922    None      None      None  2024-03-29            festivo   \n",
      "2         02922    None      None      None  2024-05-02            festivo   \n",
      "3         02922    None      None      None  2024-05-15            festivo   \n",
      "4         02922    None      None      None  2024-07-25            festivo   \n",
      "...         ...     ...       ...       ...         ...                ...   \n",
      "1738      02160    None      None      None  2025-04-17  Festivo2025-04-17   \n",
      "1739      02160    None      None      None  2025-06-21  Festivo2025-06-21   \n",
      "1740      02160    None      None      None  2025-11-01  Festivo2025-11-01   \n",
      "1741      02160    None      None      None  2025-12-06  Festivo2025-12-06   \n",
      "1742      02163    None      None      None  2025-04-17  Festivo2025-04-17   \n",
      "\n",
      "      tipo feriado_fixo  \n",
      "0        2            N  \n",
      "1        2            N  \n",
      "2        2            N  \n",
      "3        2            N  \n",
      "4        2            N  \n",
      "...    ...          ...  \n",
      "1738     2            N  \n",
      "1739     2            N  \n",
      "1740     2            N  \n",
      "1741     2            N  \n",
      "1742     2            N  \n",
      "\n",
      "[1743 rows x 8 columns]\n",
      "df_estrutura_wfm:      fk_unidade        unidade  fk_secao  \\\n",
      "0         U0001        Tlantic         1   \n",
      "1         U0001        Tlantic         2   \n",
      "2         01015     HP LEGANES  10159002   \n",
      "3         01015     HP LEGANES  10159002   \n",
      "4         01015     HP LEGANES  10159003   \n",
      "...         ...            ...       ...   \n",
      "2772      14443  SM S FERNANDO     17682   \n",
      "2773      14443  SM S FERNANDO     17682   \n",
      "2774      14443  SM S FERNANDO     17682   \n",
      "2775      14443  SM S FERNANDO     17682   \n",
      "2776      14443  SM S FERNANDO     17682   \n",
      "\n",
      "                                         secao  fk_tipo_posto  \\\n",
      "0                                     Sec√ß√£o 1              1   \n",
      "1                                     Sec√ß√£o 2              2   \n",
      "2              PGC-Bodega y Bebidas y graneles            178   \n",
      "3              PGC-Bodega y Bebidas y graneles           3370   \n",
      "4     PGC-Droguer√≠a, Perfu, Parafarmacia, Bebe            179   \n",
      "...                                        ...            ...   \n",
      "2772                               SM FERNANDO           5186   \n",
      "2773                               SM FERNANDO           5188   \n",
      "2774                               SM FERNANDO           5189   \n",
      "2775                               SM FERNANDO           5190   \n",
      "2776                               SM FERNANDO           5192   \n",
      "\n",
      "                  tipo_posto  \n",
      "0                       TP01  \n",
      "1                       TP02  \n",
      "2                 REPOSICI√ìN  \n",
      "3                      OTROS  \n",
      "4                 REPOSICI√ìN  \n",
      "...                      ...  \n",
      "2772               PGC COMUN  \n",
      "2773       FRUTAS Y VERDURAS  \n",
      "2774  PANADERIA Y PASTELERIA  \n",
      "2775    PESCADERIA MOSTRADOR  \n",
      "2776                LIMPIEZA  \n",
      "\n",
      "[2777 rows x 6 columns]\n",
      "df_estimativas_raw: Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------------------------------\n",
      "2025-06-25 16:30:57,734 |     INFO | df_feriados_filtered columns: ['fk_unidade', 'fk_pais', 'fk_estado', 'fk_cidade', 'database', 'descricao', 'tipo', 'feriado_fixo']\n",
      "   ‚úÖ Estimativas transformations completed\n",
      "2025-06-25 16:31:11,069 |     INFO | Starting load_ma_bd processing\n",
      "2025-06-25 16:31:11,156 |     INFO | teste entre novo convenio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:893: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  output_final = output_final.fillna(0)\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1091: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matriz_ma[non_date_columns] = matriz_ma[non_date_columns].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:31:11,214 |     INFO | teste entre novo convenio\n",
      "2025-06-25 16:31:11,350 |    ERROR | Empleado 5039237 sin suficiente LQ para fines de semana de calidad\n",
      "2025-06-25 16:31:11,352 |     INFO | columnes matriz a: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato']\n",
      "2025-06-25 16:31:11,371 |     INFO | load_ma_bd completed successfully. Processed 13 employees.\n",
      "   ‚úÖ Colaborador transformations completed\n",
      "2025-06-25 16:31:11,380 |     INFO | Starting load_m2_bd processing\n",
      "2025-06-25 16:31:11,384 |     INFO | DEBUG: start_date=2025-01-01, end_date=2025-12-31\n",
      "2025-06-25 16:31:11,387 |     INFO | DEBUG: matriz_ma shape=(13, 54)\n",
      "2025-06-25 16:31:11,394 |     INFO | DEBUG: all_colab_pad length=13\n",
      "2025-06-25 16:31:11,409 |     INFO | DEBUG: date_range length=365\n",
      "2025-06-25 16:31:11,427 |     INFO | DEBUG: dia_row length=731, turno_row length=731\n",
      "2025-06-25 16:31:11,519 |     INFO | DEBUG: After headers, matrix shape=(3, 731)\n",
      "2025-06-25 16:31:11,902 |     INFO | DEBUG: Final matrix shape=(16, 731)\n",
      "2025-06-25 16:31:11,910 |     INFO | DEBUG: Successfully stored df_calendario\n",
      "   ‚úÖ Calendario transformations completed\n",
      "\n",
      "üîç Debug matriz2_bk before func_inicializa:\n",
      "   Shape: (16, 731)\n",
      "   First few rows:\n",
      "          0           1           2           3           4           5    \\\n",
      "0         Dia  2025-01-01  2025-01-01  2025-01-02  2025-01-02  2025-01-03   \n",
      "1       TURNO           M           T           M           T           M   \n",
      "2    TIPO_DIA           -           -           -           -           -   \n",
      "3  0005016794           -           -           -           -           -   \n",
      "4  0005037932           -           -           -           -           -   \n",
      "\n",
      "          6           7           8           9    ...         721  \\\n",
      "0  2025-01-03  2025-01-04  2025-01-04  2025-01-05  ...  2025-12-27   \n",
      "1           T           M           T           M  ...           M   \n",
      "2           -           -           -           -  ...           -   \n",
      "3           -           -           -           -  ...           -   \n",
      "4           -           -           -           -  ...           -   \n",
      "\n",
      "          722         723         724         725         726         727  \\\n",
      "0  2025-12-27  2025-12-28  2025-12-28  2025-12-29  2025-12-29  2025-12-30   \n",
      "1           T           M           T           M           T           M   \n",
      "2           -           -           -           -           -           -   \n",
      "3           -           -           -           -           -           -   \n",
      "4           -           -           -           -           -           -   \n",
      "\n",
      "          728         729         730  \n",
      "0  2025-12-30  2025-12-31  2025-12-31  \n",
      "1           T           M           T  \n",
      "2           -           -           -  \n",
      "3           -           -           -  \n",
      "4           -           -           -  \n",
      "\n",
      "[5 rows x 731 columns]\n",
      "   Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730]\n",
      "--------------------------------\n",
      "Pos-tratamento\n",
      "df_granularidade:       fk_unidade     unidade  fk_secao               secao  fk_tipo_posto  \\\n",
      "0          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "1          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "2          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "3          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "4          01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "...          ...         ...       ...                 ...            ...   \n",
      "23720      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23721      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23722      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23723      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "23724      01015  HP LEGANES  10150184  PF MOST-Pescaderia            153   \n",
      "\n",
      "      tipo_posto       data            hora_ini  pessoas_estimado  \\\n",
      "0       VENTA PF 2025-01-01 2000-01-01 06:00:00                 0   \n",
      "1       VENTA PF 2025-01-01 2000-01-01 06:15:00                 0   \n",
      "2       VENTA PF 2025-01-01 2000-01-01 06:30:00                 0   \n",
      "3       VENTA PF 2025-01-01 2000-01-01 06:45:00                 0   \n",
      "4       VENTA PF 2025-01-01 2000-01-01 07:00:00                 0   \n",
      "...          ...        ...                 ...               ...   \n",
      "23720   VENTA PF 2025-03-11 2000-01-01 17:00:00                 1   \n",
      "23721   VENTA PF 2025-03-11 2000-01-01 17:15:00                 1   \n",
      "23722   VENTA PF 2025-03-11 2000-01-01 17:30:00                 1   \n",
      "23723   VENTA PF 2025-03-11 2000-01-01 17:45:00                 1   \n",
      "23724   VENTA PF 2025-03-11 2000-01-01 18:00:00                 2   \n",
      "\n",
      "       pessoas_min  pessoas_final  \n",
      "0                0              0  \n",
      "1                0              0  \n",
      "2                0              0  \n",
      "3                0              0  \n",
      "4                3              3  \n",
      "...            ...            ...  \n",
      "23720            2              2  \n",
      "23721            2              2  \n",
      "23722            2              2  \n",
      "23723            2              2  \n",
      "23724            2              2  \n",
      "\n",
      "[23725 rows x 11 columns]\n",
      "df_estimativas_raw:           data  media_turno  max_turno  min_turno  sd_turno turno  \\\n",
      "0   2025-01-01          0.0        0.0        0.0       0.0     M   \n",
      "1   2025-01-02          0.0        0.0        0.0       0.0     M   \n",
      "2   2025-01-03          0.0        0.0        0.0       0.0     M   \n",
      "3   2025-01-04          0.0        0.0        0.0       0.0     M   \n",
      "4   2025-01-05          0.0        0.0        0.0       0.0     M   \n",
      "..         ...          ...        ...        ...       ...   ...   \n",
      "725 2025-12-27          0.0        0.0        0.0       0.0     T   \n",
      "726 2025-12-28          0.0        0.0        0.0       0.0     T   \n",
      "727 2025-12-29          0.0        0.0        0.0       0.0     T   \n",
      "728 2025-12-30          0.0        0.0        0.0       0.0     T   \n",
      "729 2025-12-31          0.0        0.0        0.0       0.0     T   \n",
      "\n",
      "    fk_tipo_posto    data_turno  \n",
      "0            None  2025-01-01_M  \n",
      "1            None  2025-01-02_M  \n",
      "2            None  2025-01-03_M  \n",
      "3            None  2025-01-04_M  \n",
      "4            None  2025-01-05_M  \n",
      "..            ...           ...  \n",
      "725          None  2025-12-27_T  \n",
      "726          None  2025-12-28_T  \n",
      "727          None  2025-12-29_T  \n",
      "728          None  2025-12-30_T  \n",
      "729          None  2025-12-31_T  \n",
      "\n",
      "[730 rows x 8 columns]\n",
      "--------------------------------\n",
      "\n",
      "üîç Debug raw_data['df_estimativas'] before func_inicializa:\n",
      "   Shape: (730, 8)\n",
      "   Columns: ['data', 'media_turno', 'max_turno', 'min_turno', 'sd_turno', 'turno', 'fk_tipo_posto', 'data_turno']\n",
      "   First few rows:\n",
      "        data  media_turno  max_turno  min_turno  sd_turno turno fk_tipo_posto  \\\n",
      "0 2025-01-01          0.0        0.0        0.0       0.0     M          None   \n",
      "1 2025-01-02          0.0        0.0        0.0       0.0     M          None   \n",
      "2 2025-01-03          0.0        0.0        0.0       0.0     M          None   \n",
      "3 2025-01-04          0.0        0.0        0.0       0.0     M          None   \n",
      "4 2025-01-05          0.0        0.0        0.0       0.0     M          None   \n",
      "\n",
      "     data_turno  \n",
      "0  2025-01-01_M  \n",
      "1  2025-01-02_M  \n",
      "2  2025-01-03_M  \n",
      "3  2025-01-04_M  \n",
      "4  2025-01-05_M  \n",
      "2025-06-25 16:31:11,997 |     INFO | Closed database session\n",
      "2025-06-25 16:31:12,000 |     INFO | Disposed database engine\n",
      "\n",
      "üéâ Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "with data_manager:\n",
    "    # =============================================================================\n",
    "    # 4.3 PERFORM DATA TRANSFORMATIONS (Stage 3)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 3: Performing data transformations...\")\n",
    "    \n",
    "    try:\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Pre-tratamento\")\n",
    "        print(f\"df_granularidade: {data_model.auxiliary_data['df_granularidade']}\")\n",
    "        print(f\"df_faixa_horario: {data_model.auxiliary_data['df_faixa_horario']}\")\n",
    "        print(f\"df_feriados: {data_model.auxiliary_data['df_feriados']}\")\n",
    "        print(f\"df_estrutura_wfm: {data_model.auxiliary_data['df_estrutura_wfm']}\")\n",
    "        print(f\"df_estimativas_raw: {data_model.raw_data['df_estimativas']}\")\n",
    "        print(\"--------------------------------\")\n",
    "        # Load estimativas transformations\n",
    "        success = data_model.load_estimativas_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Estimativas transformations completed\")\n",
    "        \n",
    "        # Load colaborador transformations  \n",
    "        success = data_model.load_colaborador_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Colaborador transformations completed\")\n",
    "        \n",
    "        # Load calendario transformations\n",
    "        success = data_model.load_calendario_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Calendario transformations completed\")\n",
    "        \n",
    "        # Store matriz2_bk before func_inicializa\n",
    "        data_model.medium_data['matriz2_bk'] = data_model.raw_data['df_calendario'].copy()\n",
    "        \n",
    "        # Debug: Print matriz2_bk info\n",
    "        matriz2_bk = data_model.medium_data['matriz2_bk']\n",
    "        print(f\"\\nüîç Debug matriz2_bk before func_inicializa:\")\n",
    "        print(f\"   Shape: {matriz2_bk.shape}\")\n",
    "        print(f\"   First few rows:\\n{matriz2_bk.head()}\")\n",
    "        print(f\"   Columns: {matriz2_bk.columns.tolist()}\")\n",
    "\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Pos-tratamento\")\n",
    "        print(f\"df_granularidade: {data_model.auxiliary_data['df_granularidade']}\")\n",
    "        print(f\"df_estimativas_raw: {data_model.raw_data['df_estimativas']}\")\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "        # Debug: Print raw_data['df_estimativas'] before func_inicializa\n",
    "        print(\"\\nüîç Debug raw_data['df_estimativas'] before func_inicializa:\")\n",
    "        df_est = data_model.raw_data['df_estimativas']\n",
    "        print(f\"   Shape: {df_est.shape}\")\n",
    "        print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "        print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba40682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          data  media_turno  max_turno  min_turno  sd_turno turno  \\\n",
      "0   2025-01-01          0.0        0.0        0.0       0.0     M   \n",
      "1   2025-01-02          0.0        0.0        0.0       0.0     M   \n",
      "2   2025-01-03          0.0        0.0        0.0       0.0     M   \n",
      "3   2025-01-04          0.0        0.0        0.0       0.0     M   \n",
      "4   2025-01-05          0.0        0.0        0.0       0.0     M   \n",
      "..         ...          ...        ...        ...       ...   ...   \n",
      "725 2025-12-27          0.0        0.0        0.0       0.0     T   \n",
      "726 2025-12-28          0.0        0.0        0.0       0.0     T   \n",
      "727 2025-12-29          0.0        0.0        0.0       0.0     T   \n",
      "728 2025-12-30          0.0        0.0        0.0       0.0     T   \n",
      "729 2025-12-31          0.0        0.0        0.0       0.0     T   \n",
      "\n",
      "    fk_tipo_posto    data_turno  \n",
      "0            None  2025-01-01_M  \n",
      "1            None  2025-01-02_M  \n",
      "2            None  2025-01-03_M  \n",
      "3            None  2025-01-04_M  \n",
      "4            None  2025-01-05_M  \n",
      "..            ...           ...  \n",
      "725          None  2025-12-27_T  \n",
      "726          None  2025-12-28_T  \n",
      "727          None  2025-12-29_T  \n",
      "728          None  2025-12-30_T  \n",
      "729          None  2025-12-31_T  \n",
      "\n",
      "[730 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_model.raw_data['df_estimativas'])\n",
    "print(data_model.raw_data['df_colaborador'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b68836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:32:13,200 |     INFO | Connected to database: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "2025-06-25 16:32:13,205 |     INFO | === Debug matrizB_og (df_estimativas) ===\n",
      "2025-06-25 16:32:13,214 |     INFO | Shape: (730, 8)\n",
      "2025-06-25 16:32:13,217 |     INFO | Columns: ['data', 'media_turno', 'max_turno', 'min_turno', 'sd_turno', 'turno', 'fk_tipo_posto', 'data_turno']\n",
      "2025-06-25 16:32:13,231 |     INFO | First few rows:\n",
      "        data  media_turno  max_turno  min_turno  sd_turno turno fk_tipo_posto  \\\n",
      "0 2025-01-01          0.0        0.0        0.0       0.0     M          None   \n",
      "1 2025-01-02          0.0        0.0        0.0       0.0     M          None   \n",
      "2 2025-01-03          0.0        0.0        0.0       0.0     M          None   \n",
      "3 2025-01-04          0.0        0.0        0.0       0.0     M          None   \n",
      "4 2025-01-05          0.0        0.0        0.0       0.0     M          None   \n",
      "\n",
      "     data_turno  \n",
      "0  2025-01-01_M  \n",
      "1  2025-01-02_M  \n",
      "2  2025-01-03_M  \n",
      "3  2025-01-04_M  \n",
      "4  2025-01-05_M  \n",
      "2025-06-25 16:32:13,234 |     INFO | =====================================\n",
      "2025-06-25 16:32:13,240 |     INFO | matriz2_og shape: (16, 731)\n",
      "2025-06-25 16:32:13,266 |     INFO | matriz2_og first few rows:\n",
      "          0           1           2           3           4           5    \\\n",
      "0         Dia  2025-01-01  2025-01-01  2025-01-02  2025-01-02  2025-01-03   \n",
      "1       TURNO           M           T           M           T           M   \n",
      "2    TIPO_DIA           -           -           -           -           -   \n",
      "3  0005016794           -           -           -           -           -   \n",
      "4  0005037932           -           -           -           -           -   \n",
      "\n",
      "          6           7           8           9    ...         721  \\\n",
      "0  2025-01-03  2025-01-04  2025-01-04  2025-01-05  ...  2025-12-27   \n",
      "1           T           M           T           M  ...           M   \n",
      "2           -           -           -           -  ...           -   \n",
      "3           -           -           -           -  ...           -   \n",
      "4           -           -           -           -  ...           -   \n",
      "\n",
      "          722         723         724         725         726         727  \\\n",
      "0  2025-12-27  2025-12-28  2025-12-28  2025-12-29  2025-12-29  2025-12-30   \n",
      "1           T           M           T           M           T           M   \n",
      "2           -           -           -           -           -           -   \n",
      "3           -           -           -           -           -           -   \n",
      "4           -           -           -           -           -           -   \n",
      "\n",
      "          728         729         730  \n",
      "0  2025-12-30  2025-12-31  2025-12-31  \n",
      "1           T           M           T  \n",
      "2           -           -           -  \n",
      "3           -           -           -  \n",
      "4           -           -           -  \n",
      "\n",
      "[5 rows x 731 columns]\n",
      "2025-06-25 16:32:13,269 |     INFO | matriz2_og first column unique values: ['Dia' 'TURNO' 'TIPO_DIA' '0005016794' '0005037932' '0005038542'\n",
      " '0005003281' '0000155613' '0000155612' '0005038307' '0000155550'\n",
      " '0005036116' '0005006519' '0000375558' '0000155540' '0005039237']\n",
      "2025-06-25 16:32:13,279 |     INFO | TURNO row exists: True\n",
      "2025-06-25 16:32:13,281 |     INFO | Dia row exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1419: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1420: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:32:15,229 |     INFO | Columns in matrizA_og after processing: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato', 'ld', 'l_dom', 'lq_og', 'total_dom_fes', 'total_fes', 'total_holidays', 'descansos_atrb', 'COLABORADOR', 'LD_at', 'LQ_at', 'LRES_at', 'CXX_at', 'C2D_at', 'C3D_at']\n",
      "2025-06-25 16:32:40,094 |     INFO | matrizB_m:            data  media_turno  max_turno  min_turno  sd_turno turno  \\\n",
      "0    2025-01-01          0.0        0.0        0.0       0.0     M   \n",
      "1    2025-01-02          0.0        0.0        0.0       0.0     M   \n",
      "2    2025-01-03          0.0        0.0        0.0       0.0     M   \n",
      "3    2025-01-04          0.0        0.0        0.0       0.0     M   \n",
      "4    2025-01-05          0.0        0.0        0.0       0.0     M   \n",
      "..          ...          ...        ...        ...       ...   ...   \n",
      "360  2025-12-27          0.0        0.0        0.0       0.0     M   \n",
      "361  2025-12-28          0.0        0.0        0.0       0.0     M   \n",
      "362  2025-12-29          0.0        0.0        0.0       0.0     M   \n",
      "363  2025-12-30          0.0        0.0        0.0       0.0     M   \n",
      "364  2025-12-31          0.0        0.0        0.0       0.0     M   \n",
      "\n",
      "    fk_tipo_posto    data_turno  \n",
      "0            None  2025-01-01_M  \n",
      "1            None  2025-01-02_M  \n",
      "2            None  2025-01-03_M  \n",
      "3            None  2025-01-04_M  \n",
      "4            None  2025-01-05_M  \n",
      "..            ...           ...  \n",
      "360          None  2025-12-27_M  \n",
      "361          None  2025-12-28_M  \n",
      "362          None  2025-12-29_M  \n",
      "363          None  2025-12-30_M  \n",
      "364          None  2025-12-31_M  \n",
      "\n",
      "[365 rows x 8 columns]\n",
      "2025-06-25 16:32:40,097 |     INFO | trab_manha:            DATA TURNO   +H\n",
      "0    2025-01-01     M  0.0\n",
      "1    2025-01-02     M  0.0\n",
      "2    2025-01-03     M  0.0\n",
      "3    2025-01-04     M  0.0\n",
      "4    2025-01-05     M  0.0\n",
      "..          ...   ...  ...\n",
      "359  2025-12-26     M  0.0\n",
      "360  2025-12-27     M  0.0\n",
      "361  2025-12-28     M  0.0\n",
      "362  2025-12-29     M  0.0\n",
      "363  2025-12-30     M  0.0\n",
      "\n",
      "[364 rows x 3 columns]\n",
      "2025-06-25 16:32:40,117 |     INFO | matrizB_t:            data  media_turno  max_turno  min_turno  sd_turno turno  \\\n",
      "0    2025-01-01          0.0        0.0        0.0       0.0     T   \n",
      "1    2025-01-02          0.0        0.0        0.0       0.0     T   \n",
      "2    2025-01-03          0.0        0.0        0.0       0.0     T   \n",
      "3    2025-01-04          0.0        0.0        0.0       0.0     T   \n",
      "4    2025-01-05          0.0        0.0        0.0       0.0     T   \n",
      "..          ...          ...        ...        ...       ...   ...   \n",
      "360  2025-12-27          0.0        0.0        0.0       0.0     T   \n",
      "361  2025-12-28          0.0        0.0        0.0       0.0     T   \n",
      "362  2025-12-29          0.0        0.0        0.0       0.0     T   \n",
      "363  2025-12-30          0.0        0.0        0.0       0.0     T   \n",
      "364  2025-12-31          0.0        0.0        0.0       0.0     T   \n",
      "\n",
      "    fk_tipo_posto    data_turno   +H  \n",
      "0            None  2025-01-01_T  0.0  \n",
      "1            None  2025-01-02_T  0.0  \n",
      "2            None  2025-01-03_T  0.0  \n",
      "3            None  2025-01-04_T  0.0  \n",
      "4            None  2025-01-05_T  0.0  \n",
      "..            ...           ...  ...  \n",
      "360          None  2025-12-27_T  0.0  \n",
      "361          None  2025-12-28_T  0.0  \n",
      "362          None  2025-12-29_T  0.0  \n",
      "363          None  2025-12-30_T  0.0  \n",
      "364          None  2025-12-31_T  NaN  \n",
      "\n",
      "[365 rows x 9 columns]\n",
      "2025-06-25 16:32:40,129 |     INFO | matrizB_ini:            data  media_turno  max_turno  min_turno  sd_turno turno  \\\n",
      "0    2025-01-01          0.0        0.0        0.0       0.0     M   \n",
      "1    2025-01-02          0.0        0.0        0.0       0.0     M   \n",
      "2    2025-01-03          0.0        0.0        0.0       0.0     M   \n",
      "3    2025-01-04          0.0        0.0        0.0       0.0     M   \n",
      "4    2025-01-05          0.0        0.0        0.0       0.0     M   \n",
      "..          ...          ...        ...        ...       ...   ...   \n",
      "725  2025-12-27          0.0        0.0        0.0       0.0     T   \n",
      "726  2025-12-28          0.0        0.0        0.0       0.0     T   \n",
      "727  2025-12-29          0.0        0.0        0.0       0.0     T   \n",
      "728  2025-12-30          0.0        0.0        0.0       0.0     T   \n",
      "729  2025-12-31          0.0        0.0        0.0       0.0     T   \n",
      "\n",
      "    fk_tipo_posto    data_turno   +H  \n",
      "0            None  2025-01-01_M  0.0  \n",
      "1            None  2025-01-02_M  0.0  \n",
      "2            None  2025-01-03_M  0.0  \n",
      "3            None  2025-01-04_M  0.0  \n",
      "4            None  2025-01-05_M  0.0  \n",
      "..            ...           ...  ...  \n",
      "725          None  2025-12-27_T  0.0  \n",
      "726          None  2025-12-28_T  0.0  \n",
      "727          None  2025-12-29_T  0.0  \n",
      "728          None  2025-12-30_T  0.0  \n",
      "729          None  2025-12-31_T  NaN  \n",
      "\n",
      "[730 rows x 9 columns]\n",
      "2025-06-25 16:32:40,180 |     INFO | func_inicializa MatrizB creation completed successfully\n",
      "2025-06-25 16:32:40,182 |     INFO | func_inicializa completed successfully\n",
      "   ‚úÖ func_inicializa completed\n",
      "\n",
      "üîç Debug medium_data['df_estimativas'] after func_inicializa:\n",
      "   Shape: (730, 13)\n",
      "   Columns: ['data', 'media_turno', 'max_turno', 'min_turno', 'sd_turno', 'turno', 'fk_tipo_posto', 'data_turno', '+H', 'aux', 'pess_obj', 'diff', 'WDAY']\n",
      "   First few rows:\n",
      "        data  media_turno  max_turno  min_turno  sd_turno turno fk_tipo_posto  \\\n",
      "0 2025-01-01          0.0        0.0        1.0       0.0     M          None   \n",
      "1 2025-01-02          0.0        0.0        1.0       0.0     M          None   \n",
      "2 2025-01-03          0.0        0.0        1.0       0.0     M          None   \n",
      "3 2025-01-04          0.0        0.0        1.0       0.0     M          None   \n",
      "4 2025-01-05          0.0        0.0        1.0       0.0     M          None   \n",
      "\n",
      "     data_turno   +H  aux  pess_obj  diff  WDAY  \n",
      "0  2025-01-01_M  0.0  0.0       0.0   0.0     3  \n",
      "1  2025-01-02_M  0.0  0.0       0.0   0.0     4  \n",
      "2  2025-01-03_M  0.0  0.0       0.0   0.0     5  \n",
      "3  2025-01-04_M  0.0  0.0       0.0   0.0     6  \n",
      "4  2025-01-05_M  0.0  0.0       0.0   0.0     7  \n",
      "2025-06-25 16:32:40,196 |     INFO | Closed database session\n",
      "2025-06-25 16:32:40,198 |     INFO | Disposed database engine\n",
      "\n",
      "üéâ Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "with data_manager:\n",
    "    try: \n",
    "        # Perform func_inicializa\n",
    "        success = data_model.func_inicializa(\n",
    "            start_date=external_call_data['start_date'],\n",
    "            end_date=external_call_data['end_date'],\n",
    "            fer=data_model.auxiliary_data.get('df_festivos'),\n",
    "            closed_days=data_model.auxiliary_data.get('df_closed_days')\n",
    "        )\n",
    "        if success:\n",
    "            print(\"   ‚úÖ func_inicializa completed\")\n",
    "            \n",
    "            # Debug: Print medium_data['df_estimativas'] after func_inicializa\n",
    "            print(\"\\nüîç Debug medium_data['df_estimativas'] after func_inicializa:\")\n",
    "            df_est = data_model.medium_data['df_estimativas']\n",
    "            print(f\"   Shape: {df_est.shape}\")\n",
    "            print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "            print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "585239e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Organizing DataFrames for interactive access...\n",
      "\n",
      "üìã AVAILABLE DATAFRAMES\n",
      "======================================================================\n",
      "\n",
      "üóÇÔ∏è AUXILIARY:\n",
      "   üìã messages_df               ‚Üí      0 rows √ó   0 columns\n",
      "   üìã params_lq                 ‚Üí      5 rows √ó   2 columns\n",
      "   üìã valid_emp                 ‚Üí     14 rows √ó   8 columns\n",
      "   üìã colabs_id_list            ‚Üí     14 rows √ó   0 columns\n",
      "   üìã df_festivos               ‚Üí     14 rows √ó   2 columns\n",
      "   üìã df_turnos                 ‚Üí      2 rows √ó   6 columns\n",
      "   üìã df_calendario_passado     ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_count                  ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_estrutura_wfm          ‚Üí   2777 rows √ó   6 columns\n",
      "   üìã df_feriados               ‚Üí   1743 rows √ó   8 columns\n",
      "   üìã df_faixa_horario          ‚Üí   1862 rows √ó  19 columns\n",
      "   üìã df_orcamento              ‚Üí  23725 rows √ó  11 columns\n",
      "   üìã df_granularidade          ‚Üí  23725 rows √ó  11 columns\n",
      "   üìã df_calendario_past        ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_ausencias_ferias       ‚Üí    803 rows √ó   7 columns\n",
      "   üìã df_ciclos_90              ‚Üí      0 rows √ó   0 columns\n",
      "\n",
      "üìÅ RAW:\n",
      "   üìã df_calendario             ‚Üí     16 rows √ó 731 columns\n",
      "   üìã df_colaborador            ‚Üí     13 rows √ó  54 columns\n",
      "   üìã df_estimativas            ‚Üí    730 rows √ó   8 columns\n",
      "\n",
      "‚öôÔ∏è MEDIUM (Transformed):\n",
      "   üìã df_calendario             ‚Üí   9488 rows √ó  14 columns\n",
      "   üìã df_colaborador            ‚Üí     13 rows √ó  22 columns\n",
      "   üìã df_estimativas            ‚Üí    730 rows √ó  13 columns\n",
      "   üìã matriz2_bk                ‚Üí     16 rows √ó 731 columns\n",
      "   üìã matrizA_bk_og             ‚Üí     13 rows √ó  21 columns\n",
      "   üìã matriz_data_turno_bk      ‚Üí      1 rows √ó   1 columns\n",
      "\n",
      "üíé RARE (Algorithm Results): (no DataFrames yet)\n",
      "\n",
      "üìä FORMATTED (Final): (no DataFrames yet)\n",
      "\n",
      "üîó QUICK ACCESS VARIABLES\n",
      "======================================================================\n",
      "‚úÖ valid_emp           ‚Üí (14, 8)\n",
      "‚úÖ df_colaborador      ‚Üí (13, 54)\n",
      "‚úÖ df_estimativas      ‚Üí (730, 8)\n",
      "‚úÖ df_calendario       ‚Üí (16, 731)\n",
      "‚úÖ matriz2_bk          ‚Üí (16, 731)\n",
      "\n",
      "üõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\n",
      "======================================================================\n",
      "üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\n",
      "üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\n",
      "üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\n",
      "üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\n",
      "üìä df_info()                                  ‚Üí Show all DataFrames info\n",
      "\n",
      "üí° EXAMPLE USAGE:\n",
      "======================================================================\n",
      "# Explore specific DataFrames\n",
      "explore_df(valid_emp, 'Valid Employees')\n",
      "explore_df(df_colaborador, 'Employee Details')\n",
      "\n",
      "# Compare DataFrames\n",
      "compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\n",
      "\n",
      "# Show sample data\n",
      "show_sample_data(raw_dataframes, 'Raw Data', 3)\n",
      "\n",
      "# Search for specific columns\n",
      "search_columns('matricula')\n",
      "search_columns('data')\n",
      "\n",
      "# Access DataFrames directly\n",
      "valid_emp.head()\n",
      "df_colaborador.describe()\n",
      "matrizA_bk.columns\n",
      "\n",
      "üéØ DIRECT ACCESS TO PROJECT DATA:\n",
      "======================================================================\n",
      "üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\n",
      "üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\n",
      "‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\n",
      "üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\n",
      "üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\n",
      "\n",
      "üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\n",
      "üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\n",
      "‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\n",
      "\n",
      "‚ú® READY FOR INTERACTIVE DEVELOPMENT!\n",
      "üîß All project DataFrames are loaded and available in memory\n",
      "üìù Use the utility functions above to explore and analyze the data\n",
      "üöÄ Start developing your data transformations!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 5. ORGANIZE DATAFRAMES FOR EASY ACCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Organizing DataFrames for interactive access...\")\n",
    "\n",
    "# Extract all DataFrames from the data model\n",
    "auxiliary_dataframes = {}\n",
    "raw_dataframes = {}\n",
    "medium_dataframes = {}\n",
    "rare_dataframes = {}\n",
    "formatted_dataframes = {}\n",
    "\n",
    "# Auxiliary data\n",
    "for key, value in data_model.auxiliary_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        auxiliary_dataframes[key] = value\n",
    "\n",
    "# Raw data  \n",
    "for key, value in data_model.raw_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        raw_dataframes[key] = value\n",
    "\n",
    "# Medium data (transformed)\n",
    "for key, value in data_model.medium_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        medium_dataframes[key] = value\n",
    "\n",
    "# Rare data (algorithm results)\n",
    "for key, value in data_model.rare_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        rare_dataframes[key] = value\n",
    "\n",
    "# Formatted data (final output)\n",
    "for key, value in data_model.formatted_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        formatted_dataframes[key] = value\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DISPLAY AVAILABLE DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã AVAILABLE DATAFRAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_dataframes = {\n",
    "    \"üóÇÔ∏è AUXILIARY\": auxiliary_dataframes,\n",
    "    \"üìÅ RAW\": raw_dataframes, \n",
    "    \"‚öôÔ∏è MEDIUM (Transformed)\": medium_dataframes,\n",
    "    \"üíé RARE (Algorithm Results)\": rare_dataframes,\n",
    "    \"üìä FORMATTED (Final)\": formatted_dataframes\n",
    "}\n",
    "\n",
    "for category, dataframes in all_dataframes.items():\n",
    "    if dataframes:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: (no DataFrames yet)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. QUICK ACCESS VARIABLES AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîó QUICK ACCESS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make key DataFrames easily accessible with simple variable names\n",
    "try:\n",
    "    if 'valid_emp' in auxiliary_dataframes:\n",
    "        valid_emp = auxiliary_dataframes['valid_emp']\n",
    "        print(f\"‚úÖ valid_emp           ‚Üí {valid_emp.shape}\")\n",
    "    \n",
    "    if 'df_colaborador' in raw_dataframes:\n",
    "        df_colaborador = raw_dataframes['df_colaborador']\n",
    "        print(f\"‚úÖ df_colaborador      ‚Üí {df_colaborador.shape}\")\n",
    "    \n",
    "    if 'df_estimativas' in raw_dataframes:\n",
    "        df_estimativas = raw_dataframes['df_estimativas']\n",
    "        print(f\"‚úÖ df_estimativas      ‚Üí {df_estimativas.shape}\")\n",
    "    \n",
    "    if 'df_calendario' in raw_dataframes:\n",
    "        df_calendario = raw_dataframes['df_calendario']\n",
    "        print(f\"‚úÖ df_calendario       ‚Üí {df_calendario.shape}\")\n",
    "    \n",
    "    if 'matrizA_bk' in medium_dataframes:\n",
    "        matrizA_bk = medium_dataframes['matrizA_bk']\n",
    "        print(f\"‚úÖ matrizA_bk          ‚Üí {matrizA_bk.shape}\")\n",
    "    \n",
    "    if 'matriz2_bk' in medium_dataframes:\n",
    "        matriz2_bk = medium_dataframes['matriz2_bk']\n",
    "        print(f\"‚úÖ matriz2_bk          ‚Üí {matriz2_bk.shape}\")\n",
    "    \n",
    "    if 'matrizB_bk' in medium_dataframes:\n",
    "        matrizB_bk = medium_dataframes['matrizB_bk']\n",
    "        print(f\"‚úÖ matrizB_bk          ‚Üí {matrizB_bk.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some DataFrames may not be available yet: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. UTILITY FUNCTIONS FOR DATA EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def explore_df(df, name=\"DataFrame\"):\n",
    "    \"\"\"Explore a DataFrame with detailed information\"\"\"\n",
    "    print(f\"\\nüîç EXPLORING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nüìã Columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        print(f\"   {i+1:2d}. {col:<20} ({dtype}) - {null_count} nulls\")\n",
    "    \n",
    "    print(f\"\\nüìä First 3 rows:\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_dfs(*dataframes, names=None):\n",
    "    \"\"\"Compare multiple DataFrames\"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"DataFrame_{i+1}\" for i in range(len(dataframes))]\n",
    "    \n",
    "    print(f\"\\nüîÑ COMPARING DATAFRAMES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in zip(names, dataframes):\n",
    "        print(f\"üìã {name:<20} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    \n",
    "    # Check for common columns\n",
    "    if len(dataframes) > 1:\n",
    "        all_columns = [set(df.columns) for df in dataframes]\n",
    "        common_cols = set.intersection(*all_columns)\n",
    "        \n",
    "        print(f\"\\nüîó Common columns ({len(common_cols)}):\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "def show_sample_data(df_dict, category_name, n_rows=3):\n",
    "    \"\"\"Show sample data from DataFrames in a category\"\"\"\n",
    "    print(f\"\\nüìñ SAMPLE DATA: {category_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"\\nüîπ {name} (showing {min(n_rows, len(df))} rows):\")\n",
    "        if len(df) > 0:\n",
    "            print(df.head(n_rows).to_string())\n",
    "        else:\n",
    "            print(\"   (empty DataFrame)\")\n",
    "\n",
    "def search_columns(pattern, df_dict=None):\n",
    "    \"\"\"Search for columns matching a pattern across all DataFrames\"\"\"\n",
    "    if df_dict is None:\n",
    "        df_dict = {**auxiliary_dataframes, **raw_dataframes, **medium_dataframes}\n",
    "    \n",
    "    print(f\"\\nüîç SEARCHING COLUMNS: '{pattern}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found = False\n",
    "    for df_name, df in df_dict.items():\n",
    "        matching_cols = [col for col in df.columns if pattern.lower() in col.lower()]\n",
    "        if matching_cols:\n",
    "            found = True\n",
    "            print(f\"\\nüìã {df_name}:\")\n",
    "            for col in matching_cols:\n",
    "                print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"‚ùå No columns found matching '{pattern}'\")\n",
    "\n",
    "def df_info():\n",
    "    \"\"\"Show information about all available DataFrames\"\"\"\n",
    "    print(f\"\\nüìä ALL DATAFRAMES INFO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    categories = [\n",
    "        (\"üóÇÔ∏è AUXILIARY\", auxiliary_dataframes),\n",
    "        (\"üìÅ RAW\", raw_dataframes),\n",
    "        (\"‚öôÔ∏è MEDIUM\", medium_dataframes),\n",
    "        (\"üíé RARE\", rare_dataframes),\n",
    "        (\"üìä FORMATTED\", formatted_dataframes)\n",
    "    ]\n",
    "    \n",
    "    for category_name, df_dict in categories:\n",
    "        if df_dict:\n",
    "            print(f\"\\n{category_name}:\")\n",
    "            for name, df in df_dict.items():\n",
    "                memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "                print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} cols ({memory_mb:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. INSTRUCTIONS AND EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\")\n",
    "print(\"üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\")  \n",
    "print(\"üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\")\n",
    "print(\"üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\")\n",
    "print(\"üìä df_info()                                  ‚Üí Show all DataFrames info\")\n",
    "\n",
    "print(f\"\\nüí° EXAMPLE USAGE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"# Explore specific DataFrames\")\n",
    "print(\"explore_df(valid_emp, 'Valid Employees')\")\n",
    "print(\"explore_df(df_colaborador, 'Employee Details')\")\n",
    "print(\"\")\n",
    "print(\"# Compare DataFrames\")\n",
    "print(\"compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\")\n",
    "print(\"\")\n",
    "print(\"# Show sample data\")\n",
    "print(\"show_sample_data(raw_dataframes, 'Raw Data', 3)\")\n",
    "print(\"\")\n",
    "print(\"# Search for specific columns\")\n",
    "print(\"search_columns('matricula')\")\n",
    "print(\"search_columns('data')\")\n",
    "print(\"\")\n",
    "print(\"# Access DataFrames directly\")\n",
    "print(\"valid_emp.head()\")\n",
    "print(\"df_colaborador.describe()\")\n",
    "print(\"matrizA_bk.columns\")\n",
    "\n",
    "print(f\"\\nüéØ DIRECT ACCESS TO PROJECT DATA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\")\n",
    "print(\"üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\")  \n",
    "print(\"‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\")\n",
    "print(\"üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\")\n",
    "print(\"üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\")\n",
    "print(\"\")\n",
    "print(\"üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\")\n",
    "print(\"üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\")\n",
    "print(\"‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\")\n",
    "\n",
    "print(f\"\\n‚ú® READY FOR INTERACTIVE DEVELOPMENT!\")\n",
    "print(\"üîß All project DataFrames are loaded and available in memory\")\n",
    "print(\"üìù Use the utility functions above to explore and analyze the data\")\n",
    "print(\"üöÄ Start developing your data transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # =============================================================================\n",
    "    # 4.3 PERFORM DATA TRANSFORMATIONS (Stage 3)\n",
    "    # =============================================================================\n",
    "with data_manager:\n",
    "    print(\"\\nüîÑ Stage 3: Performing data transformations...\")\n",
    "    \n",
    "    try:\n",
    "        # Load estimativas transformations\n",
    "        success = data_model.load_estimativas_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Estimativas transformations completed\")\n",
    "        \n",
    "        # Load colaborador transformations  \n",
    "        success = data_model.load_colaborador_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Colaborador transformations completed\")\n",
    "        \n",
    "        # Load calendario transformations\n",
    "        success = data_model.load_calendario_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Calendario transformations completed\")\n",
    "        \n",
    "        # Store matriz2_bk before func_inicializa\n",
    "        data_model.medium_data['matriz2_bk'] = data_model.raw_data['df_calendario'].copy()\n",
    "        \n",
    "        # Debug: Print matriz2_bk info\n",
    "        matriz2_bk = data_model.medium_data['matriz2_bk']\n",
    "        print(f\"\\nüîç Debug matriz2_bk before func_inicializa:\")\n",
    "        print(f\"   Shape: {matriz2_bk.shape}\")\n",
    "        print(f\"   First few rows:\\n{matriz2_bk.head()}\")\n",
    "        print(f\"   Columns: {matriz2_bk.columns.tolist()}\")\n",
    "\n",
    "        # Debug: Print raw_data['df_estimativas'] before func_inicializa\n",
    "        print(\"\\nüîç Debug raw_data['df_estimativas'] before func_inicializa:\")\n",
    "        df_est = data_model.raw_data['df_estimativas']\n",
    "        print(f\"   Shape: {df_est.shape}\")\n",
    "        print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "        print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "\n",
    "        # Perform func_inicializa\n",
    "        success = data_model.func_inicializa(\n",
    "            start_date=external_call_data['start_date'],\n",
    "            end_date=external_call_data['end_date'],\n",
    "            fer=data_model.auxiliary_data.get('df_festivos'),\n",
    "            closed_days=data_model.auxiliary_data.get('df_closed_days')\n",
    "        )\n",
    "        if success:\n",
    "            print(\"   ‚úÖ func_inicializa completed\")\n",
    "            \n",
    "            # Debug: Print medium_data['df_estimativas'] after func_inicializa\n",
    "            print(\"\\nüîç Debug medium_data['df_estimativas'] after func_inicializa:\")\n",
    "            df_est = data_model.medium_data['df_estimativas']\n",
    "            print(f\"   Shape: {df_est.shape}\")\n",
    "            print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "            print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ORGANIZE DATAFRAMES FOR EASY ACCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Organizing DataFrames for interactive access...\")\n",
    "\n",
    "# Extract all DataFrames from the data model\n",
    "auxiliary_dataframes = {}\n",
    "raw_dataframes = {}\n",
    "medium_dataframes = {}\n",
    "rare_dataframes = {}\n",
    "formatted_dataframes = {}\n",
    "\n",
    "# Auxiliary data\n",
    "for key, value in data_model.auxiliary_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        auxiliary_dataframes[key] = value\n",
    "\n",
    "# Raw data  \n",
    "for key, value in data_model.raw_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        raw_dataframes[key] = value\n",
    "\n",
    "# Medium data (transformed)\n",
    "for key, value in data_model.medium_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        medium_dataframes[key] = value\n",
    "\n",
    "# Rare data (algorithm results)\n",
    "for key, value in data_model.rare_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        rare_dataframes[key] = value\n",
    "\n",
    "# Formatted data (final output)\n",
    "for key, value in data_model.formatted_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        formatted_dataframes[key] = value\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DISPLAY AVAILABLE DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã AVAILABLE DATAFRAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_dataframes = {\n",
    "    \"üóÇÔ∏è AUXILIARY\": auxiliary_dataframes,\n",
    "    \"üìÅ RAW\": raw_dataframes, \n",
    "    \"‚öôÔ∏è MEDIUM (Transformed)\": medium_dataframes,\n",
    "    \"üíé RARE (Algorithm Results)\": rare_dataframes,\n",
    "    \"üìä FORMATTED (Final)\": formatted_dataframes\n",
    "}\n",
    "\n",
    "for category, dataframes in all_dataframes.items():\n",
    "    if dataframes:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: (no DataFrames yet)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. QUICK ACCESS VARIABLES AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîó QUICK ACCESS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make key DataFrames easily accessible with simple variable names\n",
    "try:\n",
    "    if 'valid_emp' in auxiliary_dataframes:\n",
    "        valid_emp = auxiliary_dataframes['valid_emp']\n",
    "        print(f\"‚úÖ valid_emp           ‚Üí {valid_emp.shape}\")\n",
    "    \n",
    "    if 'df_colaborador' in raw_dataframes:\n",
    "        df_colaborador = raw_dataframes['df_colaborador']\n",
    "        print(f\"‚úÖ df_colaborador      ‚Üí {df_colaborador.shape}\")\n",
    "    \n",
    "    if 'df_estimativas' in raw_dataframes:\n",
    "        df_estimativas = raw_dataframes['df_estimativas']\n",
    "        print(f\"‚úÖ df_estimativas      ‚Üí {df_estimativas.shape}\")\n",
    "    \n",
    "    if 'df_calendario' in raw_dataframes:\n",
    "        df_calendario = raw_dataframes['df_calendario']\n",
    "        print(f\"‚úÖ df_calendario       ‚Üí {df_calendario.shape}\")\n",
    "    \n",
    "    if 'matrizA_bk' in medium_dataframes:\n",
    "        matrizA_bk = medium_dataframes['matrizA_bk']\n",
    "        print(f\"‚úÖ matrizA_bk          ‚Üí {matrizA_bk.shape}\")\n",
    "    \n",
    "    if 'matriz2_bk' in medium_dataframes:\n",
    "        matriz2_bk = medium_dataframes['matriz2_bk']\n",
    "        print(f\"‚úÖ matriz2_bk          ‚Üí {matriz2_bk.shape}\")\n",
    "    \n",
    "    if 'matrizB_bk' in medium_dataframes:\n",
    "        matrizB_bk = medium_dataframes['matrizB_bk']\n",
    "        print(f\"‚úÖ matrizB_bk          ‚Üí {matrizB_bk.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some DataFrames may not be available yet: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. UTILITY FUNCTIONS FOR DATA EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def explore_df(df, name=\"DataFrame\"):\n",
    "    \"\"\"Explore a DataFrame with detailed information\"\"\"\n",
    "    print(f\"\\nüîç EXPLORING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nüìã Columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        print(f\"   {i+1:2d}. {col:<20} ({dtype}) - {null_count} nulls\")\n",
    "    \n",
    "    print(f\"\\nüìä First 3 rows:\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_dfs(*dataframes, names=None):\n",
    "    \"\"\"Compare multiple DataFrames\"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"DataFrame_{i+1}\" for i in range(len(dataframes))]\n",
    "    \n",
    "    print(f\"\\nüîÑ COMPARING DATAFRAMES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in zip(names, dataframes):\n",
    "        print(f\"üìã {name:<20} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    \n",
    "    # Check for common columns\n",
    "    if len(dataframes) > 1:\n",
    "        all_columns = [set(df.columns) for df in dataframes]\n",
    "        common_cols = set.intersection(*all_columns)\n",
    "        \n",
    "        print(f\"\\nüîó Common columns ({len(common_cols)}):\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "def show_sample_data(df_dict, category_name, n_rows=3):\n",
    "    \"\"\"Show sample data from DataFrames in a category\"\"\"\n",
    "    print(f\"\\nüìñ SAMPLE DATA: {category_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"\\nüîπ {name} (showing {min(n_rows, len(df))} rows):\")\n",
    "        if len(df) > 0:\n",
    "            print(df.head(n_rows).to_string())\n",
    "        else:\n",
    "            print(\"   (empty DataFrame)\")\n",
    "\n",
    "def search_columns(pattern, df_dict=None):\n",
    "    \"\"\"Search for columns matching a pattern across all DataFrames\"\"\"\n",
    "    if df_dict is None:\n",
    "        df_dict = {**auxiliary_dataframes, **raw_dataframes, **medium_dataframes}\n",
    "    \n",
    "    print(f\"\\nüîç SEARCHING COLUMNS: '{pattern}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found = False\n",
    "    for df_name, df in df_dict.items():\n",
    "        matching_cols = [col for col in df.columns if pattern.lower() in col.lower()]\n",
    "        if matching_cols:\n",
    "            found = True\n",
    "            print(f\"\\nüìã {df_name}:\")\n",
    "            for col in matching_cols:\n",
    "                print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"‚ùå No columns found matching '{pattern}'\")\n",
    "\n",
    "def df_info():\n",
    "    \"\"\"Show information about all available DataFrames\"\"\"\n",
    "    print(f\"\\nüìä ALL DATAFRAMES INFO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    categories = [\n",
    "        (\"üóÇÔ∏è AUXILIARY\", auxiliary_dataframes),\n",
    "        (\"üìÅ RAW\", raw_dataframes),\n",
    "        (\"‚öôÔ∏è MEDIUM\", medium_dataframes),\n",
    "        (\"üíé RARE\", rare_dataframes),\n",
    "        (\"üìä FORMATTED\", formatted_dataframes)\n",
    "    ]\n",
    "    \n",
    "    for category_name, df_dict in categories:\n",
    "        if df_dict:\n",
    "            print(f\"\\n{category_name}:\")\n",
    "            for name, df in df_dict.items():\n",
    "                memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "                print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} cols ({memory_mb:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. INSTRUCTIONS AND EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\")\n",
    "print(\"üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\")  \n",
    "print(\"üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\")\n",
    "print(\"üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\")\n",
    "print(\"üìä df_info()                                  ‚Üí Show all DataFrames info\")\n",
    "\n",
    "print(f\"\\nüí° EXAMPLE USAGE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"# Explore specific DataFrames\")\n",
    "print(\"explore_df(valid_emp, 'Valid Employees')\")\n",
    "print(\"explore_df(df_colaborador, 'Employee Details')\")\n",
    "print(\"\")\n",
    "print(\"# Compare DataFrames\")\n",
    "print(\"compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\")\n",
    "print(\"\")\n",
    "print(\"# Show sample data\")\n",
    "print(\"show_sample_data(raw_dataframes, 'Raw Data', 3)\")\n",
    "print(\"\")\n",
    "print(\"# Search for specific columns\")\n",
    "print(\"search_columns('matricula')\")\n",
    "print(\"search_columns('data')\")\n",
    "print(\"\")\n",
    "print(\"# Access DataFrames directly\")\n",
    "print(\"valid_emp.head()\")\n",
    "print(\"df_colaborador.describe()\")\n",
    "print(\"matrizA_bk.columns\")\n",
    "\n",
    "print(f\"\\nüéØ DIRECT ACCESS TO PROJECT DATA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\")\n",
    "print(\"üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\")  \n",
    "print(\"‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\")\n",
    "print(\"üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\")\n",
    "print(\"üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\")\n",
    "print(\"\")\n",
    "print(\"üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\")\n",
    "print(\"üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\")\n",
    "print(\"‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\")\n",
    "\n",
    "print(f\"\\n‚ú® READY FOR INTERACTIVE DEVELOPMENT!\")\n",
    "print(\"üîß All project DataFrames are loaded and available in memory\")\n",
    "print(\"üìù Use the utility functions above to explore and analyze the data\")\n",
    "print(\"üöÄ Start developing your data transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # =============================================================================\n",
    "    # 4.3 PERFORM DATA TRANSFORMATIONS (Stage 3)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 3: Performing data transformations...\")\n",
    "    \n",
    "    try:\n",
    "        # Load estimativas transformations\n",
    "        success = data_model.load_estimativas_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Estimativas transformations completed\")\n",
    "        \n",
    "        # Load colaborador transformations  \n",
    "        success = data_model.load_colaborador_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Colaborador transformations completed\")\n",
    "        \n",
    "        # Load calendario transformations\n",
    "        success = data_model.load_calendario_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Calendario transformations completed\")\n",
    "        \n",
    "        # Store matriz2_bk before func_inicializa\n",
    "        data_model.medium_data['matriz2_bk'] = data_model.raw_data['df_calendario'].copy()\n",
    "        \n",
    "        # Debug: Print matriz2_bk info\n",
    "        matriz2_bk = data_model.medium_data['matriz2_bk']\n",
    "        print(f\"\\nüîç Debug matriz2_bk before func_inicializa:\")\n",
    "        print(f\"   Shape: {matriz2_bk.shape}\")\n",
    "        print(f\"   First few rows:\\n{matriz2_bk.head()}\")\n",
    "        print(f\"   Columns: {matriz2_bk.columns.tolist()}\")\n",
    "\n",
    "        # Debug: Print raw_data['df_estimativas'] before func_inicializa\n",
    "        print(\"\\nüîç Debug raw_data['df_estimativas'] before func_inicializa:\")\n",
    "        df_est = data_model.raw_data['df_estimativas']\n",
    "        print(f\"   Shape: {df_est.shape}\")\n",
    "        print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "        print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "\n",
    "        # Perform func_inicializa\n",
    "        success = data_model.func_inicializa(\n",
    "            start_date=external_call_data['start_date'],\n",
    "            end_date=external_call_data['end_date'],\n",
    "            fer=data_model.auxiliary_data.get('df_festivos'),\n",
    "            closed_days=data_model.auxiliary_data.get('df_closed_days')\n",
    "        )\n",
    "        if success:\n",
    "            print(\"   ‚úÖ func_inicializa completed\")\n",
    "            \n",
    "            # Debug: Print medium_data['df_estimativas'] after func_inicializa\n",
    "            print(\"\\nüîç Debug medium_data['df_estimativas'] after func_inicializa:\")\n",
    "            df_est = data_model.medium_data['df_estimativas']\n",
    "            print(f\"   Shape: {df_est.shape}\")\n",
    "            print(f\"   Columns: {df_est.columns.tolist()}\")\n",
    "            print(f\"   First few rows:\\n{df_est.head()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ORGANIZE DATAFRAMES FOR EASY ACCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Organizing DataFrames for interactive access...\")\n",
    "\n",
    "# Extract all DataFrames from the data model\n",
    "auxiliary_dataframes = {}\n",
    "raw_dataframes = {}\n",
    "medium_dataframes = {}\n",
    "rare_dataframes = {}\n",
    "formatted_dataframes = {}\n",
    "\n",
    "# Auxiliary data\n",
    "for key, value in data_model.auxiliary_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        auxiliary_dataframes[key] = value\n",
    "\n",
    "# Raw data  \n",
    "for key, value in data_model.raw_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        raw_dataframes[key] = value\n",
    "\n",
    "# Medium data (transformed)\n",
    "for key, value in data_model.medium_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        medium_dataframes[key] = value\n",
    "\n",
    "# Rare data (algorithm results)\n",
    "for key, value in data_model.rare_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        rare_dataframes[key] = value\n",
    "\n",
    "# Formatted data (final output)\n",
    "for key, value in data_model.formatted_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        formatted_dataframes[key] = value\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DISPLAY AVAILABLE DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã AVAILABLE DATAFRAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_dataframes = {\n",
    "    \"üóÇÔ∏è AUXILIARY\": auxiliary_dataframes,\n",
    "    \"üìÅ RAW\": raw_dataframes, \n",
    "    \"‚öôÔ∏è MEDIUM (Transformed)\": medium_dataframes,\n",
    "    \"üíé RARE (Algorithm Results)\": rare_dataframes,\n",
    "    \"üìä FORMATTED (Final)\": formatted_dataframes\n",
    "}\n",
    "\n",
    "for category, dataframes in all_dataframes.items():\n",
    "    if dataframes:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: (no DataFrames yet)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. QUICK ACCESS VARIABLES AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîó QUICK ACCESS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make key DataFrames easily accessible with simple variable names\n",
    "try:\n",
    "    if 'valid_emp' in auxiliary_dataframes:\n",
    "        valid_emp = auxiliary_dataframes['valid_emp']\n",
    "        print(f\"‚úÖ valid_emp           ‚Üí {valid_emp.shape}\")\n",
    "    \n",
    "    if 'df_colaborador' in raw_dataframes:\n",
    "        df_colaborador = raw_dataframes['df_colaborador']\n",
    "        print(f\"‚úÖ df_colaborador      ‚Üí {df_colaborador.shape}\")\n",
    "    \n",
    "    if 'df_estimativas' in raw_dataframes:\n",
    "        df_estimativas = raw_dataframes['df_estimativas']\n",
    "        print(f\"‚úÖ df_estimativas      ‚Üí {df_estimativas.shape}\")\n",
    "    \n",
    "    if 'df_calendario' in raw_dataframes:\n",
    "        df_calendario = raw_dataframes['df_calendario']\n",
    "        print(f\"‚úÖ df_calendario       ‚Üí {df_calendario.shape}\")\n",
    "    \n",
    "    if 'matrizA_bk' in medium_dataframes:\n",
    "        matrizA_bk = medium_dataframes['matrizA_bk']\n",
    "        print(f\"‚úÖ matrizA_bk          ‚Üí {matrizA_bk.shape}\")\n",
    "    \n",
    "    if 'matriz2_bk' in medium_dataframes:\n",
    "        matriz2_bk = medium_dataframes['matriz2_bk']\n",
    "        print(f\"‚úÖ matriz2_bk          ‚Üí {matriz2_bk.shape}\")\n",
    "    \n",
    "    if 'matrizB_bk' in medium_dataframes:\n",
    "        matrizB_bk = medium_dataframes['matrizB_bk']\n",
    "        print(f\"‚úÖ matrizB_bk          ‚Üí {matrizB_bk.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some DataFrames may not be available yet: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. UTILITY FUNCTIONS FOR DATA EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def explore_df(df, name=\"DataFrame\"):\n",
    "    \"\"\"Explore a DataFrame with detailed information\"\"\"\n",
    "    print(f\"\\nüîç EXPLORING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nüìã Columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        print(f\"   {i+1:2d}. {col:<20} ({dtype}) - {null_count} nulls\")\n",
    "    \n",
    "    print(f\"\\nüìä First 3 rows:\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_dfs(*dataframes, names=None):\n",
    "    \"\"\"Compare multiple DataFrames\"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"DataFrame_{i+1}\" for i in range(len(dataframes))]\n",
    "    \n",
    "    print(f\"\\nüîÑ COMPARING DATAFRAMES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in zip(names, dataframes):\n",
    "        print(f\"üìã {name:<20} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    \n",
    "    # Check for common columns\n",
    "    if len(dataframes) > 1:\n",
    "        all_columns = [set(df.columns) for df in dataframes]\n",
    "        common_cols = set.intersection(*all_columns)\n",
    "        \n",
    "        print(f\"\\nüîó Common columns ({len(common_cols)}):\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "def show_sample_data(df_dict, category_name, n_rows=3):\n",
    "    \"\"\"Show sample data from DataFrames in a category\"\"\"\n",
    "    print(f\"\\nüìñ SAMPLE DATA: {category_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"\\nüîπ {name} (showing {min(n_rows, len(df))} rows):\")\n",
    "        if len(df) > 0:\n",
    "            print(df.head(n_rows).to_string())\n",
    "        else:\n",
    "            print(\"   (empty DataFrame)\")\n",
    "\n",
    "def search_columns(pattern, df_dict=None):\n",
    "    \"\"\"Search for columns matching a pattern across all DataFrames\"\"\"\n",
    "    if df_dict is None:\n",
    "        df_dict = {**auxiliary_dataframes, **raw_dataframes, **medium_dataframes}\n",
    "    \n",
    "    print(f\"\\nüîç SEARCHING COLUMNS: '{pattern}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found = False\n",
    "    for df_name, df in df_dict.items():\n",
    "        matching_cols = [col for col in df.columns if pattern.lower() in col.lower()]\n",
    "        if matching_cols:\n",
    "            found = True\n",
    "            print(f\"\\nüìã {df_name}:\")\n",
    "            for col in matching_cols:\n",
    "                print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"‚ùå No columns found matching '{pattern}'\")\n",
    "\n",
    "def df_info():\n",
    "    \"\"\"Show information about all available DataFrames\"\"\"\n",
    "    print(f\"\\nüìä ALL DATAFRAMES INFO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    categories = [\n",
    "        (\"üóÇÔ∏è AUXILIARY\", auxiliary_dataframes),\n",
    "        (\"üìÅ RAW\", raw_dataframes),\n",
    "        (\"‚öôÔ∏è MEDIUM\", medium_dataframes),\n",
    "        (\"üíé RARE\", rare_dataframes),\n",
    "        (\"üìä FORMATTED\", formatted_dataframes)\n",
    "    ]\n",
    "    \n",
    "    for category_name, df_dict in categories:\n",
    "        if df_dict:\n",
    "            print(f\"\\n{category_name}:\")\n",
    "            for name, df in df_dict.items():\n",
    "                memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "                print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} cols ({memory_mb:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. INSTRUCTIONS AND EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\")\n",
    "print(\"üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\")  \n",
    "print(\"üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\")\n",
    "print(\"üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\")\n",
    "print(\"üìä df_info()                                  ‚Üí Show all DataFrames info\")\n",
    "\n",
    "print(f\"\\nüí° EXAMPLE USAGE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"# Explore specific DataFrames\")\n",
    "print(\"explore_df(valid_emp, 'Valid Employees')\")\n",
    "print(\"explore_df(df_colaborador, 'Employee Details')\")\n",
    "print(\"\")\n",
    "print(\"# Compare DataFrames\")\n",
    "print(\"compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\")\n",
    "print(\"\")\n",
    "print(\"# Show sample data\")\n",
    "print(\"show_sample_data(raw_dataframes, 'Raw Data', 3)\")\n",
    "print(\"\")\n",
    "print(\"# Search for specific columns\")\n",
    "print(\"search_columns('matricula')\")\n",
    "print(\"search_columns('data')\")\n",
    "print(\"\")\n",
    "print(\"# Access DataFrames directly\")\n",
    "print(\"valid_emp.head()\")\n",
    "print(\"df_colaborador.describe()\")\n",
    "print(\"matrizA_bk.columns\")\n",
    "\n",
    "print(f\"\\nüéØ DIRECT ACCESS TO PROJECT DATA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\")\n",
    "print(\"üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\")  \n",
    "print(\"‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\")\n",
    "print(\"üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\")\n",
    "print(\"üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\")\n",
    "print(\"\")\n",
    "print(\"üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\")\n",
    "print(\"üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\")\n",
    "print(\"‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\")\n",
    "\n",
    "print(f\"\\n‚ú® READY FOR INTERACTIVE DEVELOPMENT!\")\n",
    "print(\"üîß All project DataFrames are loaded and available in memory\")\n",
    "print(\"üìù Use the utility functions above to explore and analyze the data\")\n",
    "print(\"üöÄ Start developing your data transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug func_inicializa MatrizB Processing\n",
    "# This focuses on the specific part where df_estimativas gets processed\n",
    "\n",
    "def debug_func_inicializa_matrizb(data_model):\n",
    "    \"\"\"\n",
    "    Debug the MatrizB processing in func_inicializa where df_estimativas is handled\n",
    "    \"\"\"\n",
    "    print(\"üîç DEBUGGING func_inicializa MatrizB Processing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get the starting data\n",
    "    matrizB_og = data_model.raw_data.get('df_estimativas', pd.DataFrame()).copy()\n",
    "    matriz2_bk = data_model.medium_data.get('matriz2_bk', pd.DataFrame())\n",
    "    \n",
    "    print(f\"üìä Starting data:\")\n",
    "    print(f\"   matrizB_og (df_estimativas): {matrizB_og.shape}\")\n",
    "    print(f\"   matriz2_bk: {matriz2_bk.shape}\")\n",
    "    \n",
    "    if len(matrizB_og) == 0:\n",
    "        print(\"‚ùå matrizB_og is empty - this is the source of the problem!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìã matrizB_og columns: {list(matrizB_og.columns)}\")\n",
    "    print(f\"üìä matrizB_og sample:\")\n",
    "    print(matrizB_og.head(3))\n",
    "    \n",
    "    # Get year from matrizB_og\n",
    "    if 'data' in matrizB_og.columns:\n",
    "        ano = pd.to_datetime(matrizB_og['data'].min()).year\n",
    "        print(f\"\\nüìÖ Year from data: {ano}\")\n",
    "        \n",
    "        # Adjust minTurno for specific dates (this is from the R code)\n",
    "        special_dates = [f'{ano}-12-23', f'{ano}-12-24', f'{ano}-12-30', f'{ano}-12-31']\n",
    "        friday_dates = [f'{ano}-12-22', f'{ano}-12-29']\n",
    "        \n",
    "        matrizB_ini = matrizB_og.copy()\n",
    "        \n",
    "        # Check if the required columns exist\n",
    "        required_cols = ['min_turno', 'max_turno']\n",
    "        missing_cols = [col for col in required_cols if col not in matrizB_ini.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "            print(f\"   Available columns: {list(matrizB_ini.columns)}\")\n",
    "            return\n",
    "        \n",
    "        # Apply the special date logic\n",
    "        matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
    "        mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n",
    "        matrizB_ini.loc[mask_friday, 'min_turno'] = matrizB_ini.loc[mask_friday, 'max_turno']\n",
    "        \n",
    "        print(f\"‚úÖ Applied special date adjustments\")\n",
    "        print(f\"   matrizB_ini shape after adjustments: {matrizB_ini.shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå 'data' column not found in matrizB_og\")\n",
    "        return\n",
    "    \n",
    "    # Now the critical part - creating the +H column\n",
    "    print(f\"\\nüîÑ Creating +H column from matriz2_bk...\")\n",
    "    \n",
    "    if len(matriz2_bk) == 0:\n",
    "        print(\"‚ùå matriz2_bk is empty - cannot create +H column!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìã matriz2_bk columns: {list(matriz2_bk.columns)}\")\n",
    "    \n",
    "    # Check the logic for calculating +H for morning shifts\n",
    "    print(f\"\\nüåÖ Processing morning shifts...\")\n",
    "    \n",
    "    trab_manha_data = []\n",
    "    unique_dates = matriz2_bk['DATA'].unique() if 'DATA' in matriz2_bk.columns else []\n",
    "    \n",
    "    print(f\"   Found {len(unique_dates)} unique dates in matriz2_bk\")\n",
    "    \n",
    "    if len(unique_dates) == 0:\n",
    "        print(\"‚ùå No dates found in matriz2_bk DATA column\")\n",
    "        return\n",
    "    \n",
    "    # Sample a few dates to check the logic\n",
    "    sample_dates = unique_dates[:3] if len(unique_dates) >= 3 else unique_dates\n",
    "    \n",
    "    for date in sample_dates:\n",
    "        if date == 'TIPO_DIA':\n",
    "            continue\n",
    "            \n",
    "        day_data = matriz2_bk[(matriz2_bk['DATA'] == date) & \n",
    "                            (matriz2_bk['COLABORADOR'] != 'TIPO_DIA')].copy()\n",
    "        \n",
    "        print(f\"   üìÖ Date {date}: {len(day_data)} employee records\")\n",
    "        \n",
    "        if len(day_data) == 0:\n",
    "            print(f\"      ‚ö†Ô∏è No employee data for date {date}\")\n",
    "            continue\n",
    "        \n",
    "        # Check the TIPO_TURNO and HORARIO columns\n",
    "        if 'TIPO_TURNO' in day_data.columns and 'HORARIO' in day_data.columns:\n",
    "            morning_workers = day_data[\n",
    "                (day_data['TIPO_TURNO'] == 'M') & \n",
    "                (day_data['HORARIO'].str.contains('H|NL', case=False, na=False))\n",
    "            ]\n",
    "            print(f\"      üåÖ Morning workers: {len(morning_workers)}\")\n",
    "        else:\n",
    "            print(f\"      ‚ùå Missing TIPO_TURNO or HORARIO columns\")\n",
    "    \n",
    "    # The issue might be in the merge logic\n",
    "    print(f\"\\nüîó Checking merge logic...\")\n",
    "    \n",
    "    # Check if matrizB_ini has the expected columns for merging\n",
    "    merge_cols = ['data', 'turno']\n",
    "    available_merge_cols = [col for col in merge_cols if col in matrizB_ini.columns]\n",
    "    \n",
    "    print(f\"   Required merge columns: {merge_cols}\")\n",
    "    print(f\"   Available in matrizB_ini: {available_merge_cols}\")\n",
    "    \n",
    "    if len(available_merge_cols) != len(merge_cols):\n",
    "        print(f\"‚ùå Cannot merge - missing columns in matrizB_ini\")\n",
    "        return\n",
    "    \n",
    "    # Test the merge for morning data\n",
    "    if len(trab_manha_data) == 0:\n",
    "        # Create at least one sample to test\n",
    "        trab_manha_data = [{\n",
    "            'DATA': sample_dates[0] if len(sample_dates) > 0 else '2025-01-01',\n",
    "            'TURNO': 'M',\n",
    "            '+H': 5.0\n",
    "        }]\n",
    "    \n",
    "    trab_manha = pd.DataFrame(trab_manha_data)\n",
    "    print(f\"   trab_manha sample: {trab_manha.shape}\")\n",
    "    print(f\"   trab_manha columns: {list(trab_manha.columns)}\")\n",
    "    \n",
    "    # Test merge\n",
    "    matrizB_m = matrizB_ini[matrizB_ini['turno'] == 'M'].copy()\n",
    "    print(f\"   matrizB morning records: {len(matrizB_m)}\")\n",
    "    \n",
    "    if len(matrizB_m) > 0:\n",
    "        try:\n",
    "            merged = matrizB_m.merge(trab_manha, left_on=['data', 'turno'], \n",
    "                                   right_on=['DATA', 'TURNO'], how='left')\n",
    "            print(f\"   ‚úÖ Merge successful: {merged.shape}\")\n",
    "            print(f\"   +H column created: {'+H' in merged.columns}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Merge failed: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìã SUMMARY:\")\n",
    "    print(f\"   üî∏ matrizB_og (input): {matrizB_og.shape}\")\n",
    "    print(f\"   üî∏ Expected output should have +H column\")\n",
    "    print(f\"   üî∏ Issue likely in +H calculation or merge logic\")\n",
    "    \n",
    "    return matrizB_ini\n",
    "\n",
    "# Function to test the exact transformation\n",
    "def test_matrizb_transformation(data_model):\n",
    "    \"\"\"\n",
    "    Test the exact MatrizB transformation to see where it fails\n",
    "    \"\"\"\n",
    "    print(\"\\nüß™ TESTING MatrizB Transformation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get the raw data\n",
    "    matrizB_og = data_model.raw_data.get('df_estimativas', pd.DataFrame()).copy()\n",
    "    \n",
    "    if len(matrizB_og) == 0:\n",
    "        print(\"‚ùå Cannot test - matrizB_og is empty\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Starting with: {matrizB_og.shape}\")\n",
    "    \n",
    "    # Apply the basic transformation steps\n",
    "    try:\n",
    "        # Step 1: Convert data types\n",
    "        numeric_cols = ['max_turno', 'min_turno', 'media_turno', 'sd_turno']\n",
    "        for col in numeric_cols:\n",
    "            if col in matrizB_og.columns:\n",
    "                matrizB_og[col] = pd.to_numeric(matrizB_og[col], errors='coerce')\n",
    "                print(f\"   ‚úÖ Converted {col} to numeric\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Column {col} not found\")\n",
    "        \n",
    "        # Step 2: Add +H column (placeholder)\n",
    "        matrizB_og['+H'] = 0\n",
    "        print(f\"   ‚úÖ Added +H column\")\n",
    "        \n",
    "        # Step 3: Apply the calculation logic\n",
    "        param_pess_obj = 0.5\n",
    "        matrizB_og['aux'] = np.where(\n",
    "            matrizB_og['media_turno'] != 0,\n",
    "            matrizB_og['sd_turno'] / matrizB_og['media_turno'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        matrizB_og['pess_obj'] = np.where(\n",
    "            matrizB_og['aux'] >= param_pess_obj,\n",
    "            np.ceil(matrizB_og['media_turno']),\n",
    "            np.round(matrizB_og['media_turno'])\n",
    "        )\n",
    "        \n",
    "        matrizB_og['diff'] = matrizB_og['+H'] - matrizB_og['pess_obj']\n",
    "        \n",
    "        print(f\"   ‚úÖ Applied calculations\")\n",
    "        print(f\"   üìä Final shape: {matrizB_og.shape}\")\n",
    "        \n",
    "        # Store in medium_data to test\n",
    "        data_model.medium_data['test_df_estimativas'] = matrizB_og.copy()\n",
    "        \n",
    "        print(f\"   ‚úÖ Test successful - stored in medium_data['test_df_estimativas']\")\n",
    "        \n",
    "        return matrizB_og\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the debugging\n",
    "if 'data_model' in locals():\n",
    "    result = debug_func_inicializa_matrizb(data_model)\n",
    "    test_result = test_matrizb_transformation(data_model)\n",
    "    \n",
    "    if test_result is not None:\n",
    "        print(f\"\\n‚úÖ The transformation CAN work!\")\n",
    "        print(f\"   The issue is likely in the +H calculation logic in func_inicializa\")\n",
    "        print(f\"   Check the matriz2_bk processing section\")\n",
    "else:\n",
    "    print(\"‚ùå data_model not found. Run the main notebook first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
