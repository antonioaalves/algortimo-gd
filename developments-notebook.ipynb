{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Interactive Development Environment - Algoritmo GD Project\n",
      "======================================================================\n",
      "2025-06-12 13:10:14,475 |     INFO | Logger initialized for algoritmo_GD\n",
      "‚úÖ Project modules imported successfully\n",
      "üìÅ Project: algoritmo_GD\n",
      "üóÇÔ∏è  Root directory: c:\\ALCAMPO\\python-algorithms\\algortimo-gd\n",
      "2025-06-12 13:10:14,866 |     INFO | Logger initialized for algoritmo_GD\n",
      "\n",
      "üìã Setting up configuration and external data...\n",
      "üìä Data source: CSV files\n",
      "üìÖ Date range: 2025-01-01 to 2025-12-31\n",
      "üî¢ Process ID: 249652\n",
      "\n",
      "üîß Initializing data manager and components...\n",
      "2025-06-12 13:10:14,868 |     INFO | Logger initialized for base_data_project\n",
      "2025-06-12 13:10:14,869 |     INFO | Data manager for 'db' not registered, trying built-in managers\n",
      "2025-06-12 13:10:14,870 |     INFO | Initialized BaseDataManager\n",
      "‚úÖ Data manager created successfully\n",
      "\n",
      "üìä Loading project data into memory...\n",
      "2025-06-12 13:10:14,871 |     INFO | Initialized DescansosDataModel\n",
      "2025-06-12 13:10:14,874 |     INFO | DataContainer initialized\n",
      "‚úÖ Data model initialized\n",
      "2025-06-12 13:10:14,914 |     INFO | Connected to database: oracle+cx_oracle://ANTONIO_ALVES:4dB>(fUU77P?/@10.175.28.20:1523/?service_name=WFM_ALCAMPO_TST01\n",
      "\n",
      "üîÑ Stage 1: Loading process data...\n",
      "2025-06-12 13:10:14,915 |     INFO | Loading process data from data manager\n",
      "2025-06-12 13:10:14,916 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-12 13:10:14,919 |     INFO | Replaced {process_id} with '249652'\n",
      "2025-06-12 13:10:14,919 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\get_process_valid_employess.sql\n",
      "2025-06-12 13:10:14,920 |     INFO | Loading database data for entity 'valid_emp'\n",
      "2025-06-12 13:10:14,921 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:16,675 |     INFO | Successfully loaded 1 rows using custom query\n",
      "2025-06-12 13:10:16,677 |     INFO | valid_emp: Index(['codigo', 'fk_aviso', 'fk_unidade', 'fk_secao', 'fk_perfil', 'fk_cargo',\n",
      "       'fk_aviso_clube', 'fk_colaborador'],\n",
      "      dtype='object')\n",
      "2025-06-12 13:10:16,698 |     INFO | Date counts per year: {'2025': np.int64(365)}\n",
      "2025-06-12 13:10:16,699 |     INFO | Year with most dates is: 2025\n",
      "2025-06-12 13:10:16,701 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-12 13:10:16,703 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_params_LQ.sql\n",
      "2025-06-12 13:10:16,704 |     INFO | Loading database data for entity 'params_lq'\n",
      "2025-06-12 13:10:16,705 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:16,810 |     INFO | Successfully loaded 5 rows using custom query\n",
      "2025-06-12 13:10:16,812 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-12 13:10:16,814 |     INFO | Replaced {unit_id} with '02897'\n",
      "2025-06-12 13:10:16,816 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_festivos.sql\n",
      "2025-06-12 13:10:16,817 |     INFO | Loading database data for entity 'df_festivos'\n",
      "2025-06-12 13:10:16,818 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:16,927 |     INFO | Successfully loaded 14 rows using custom query\n",
      "2025-06-12 13:10:16,929 |     INFO | Successfully loaded 3 entities\n",
      "‚úÖ Process data loaded successfully\n",
      "   üìã Valid employees: 1 records\n",
      "   üè¢ Unit ID: 02897\n",
      "   üè≠ Section ID: 9552\n",
      "   üë§ Position IDs: [684]\n",
      "\n",
      "üîÑ Stage 2: Loading detailed data for positions...\n",
      "üìç Processing position ID: 684\n",
      "2025-06-12 13:10:16,932 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-12 13:10:16,934 |     INFO | Replaced {colabs_id} with 36891\n",
      "2025-06-12 13:10:16,935 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\qry_ma.sql\n",
      "2025-06-12 13:10:16,937 |     INFO | Loading database data for entity 'df_colaborador'\n",
      "2025-06-12 13:10:16,938 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:17,008 |     INFO | Successfully loaded 1 rows using custom query\n",
      "   ‚úÖ Colaborador info loaded\n",
      "      üìä 1 employee records\n",
      "2025-06-12 13:10:17,014 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-12 13:10:17,016 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEstruturaWFM.sql\n",
      "2025-06-12 13:10:17,017 |     INFO | Loading database data for entity 'df_estrutura_wfm'\n",
      "2025-06-12 13:10:17,018 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:18,582 |     INFO | Successfully loaded 2777 rows using custom query\n",
      "2025-06-12 13:10:18,584 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-12 13:10:18,586 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetFeriadosAbertos.sql\n",
      "2025-06-12 13:10:18,587 |     INFO | Loading database data for entity 'df_feriados'\n",
      "2025-06-12 13:10:18,589 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:19,625 |     INFO | Successfully loaded 1743 rows using custom query\n",
      "2025-06-12 13:10:19,626 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-12 13:10:19,627 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscFaixaHorario.sql\n",
      "2025-06-12 13:10:19,628 |     INFO | Loading database data for entity 'df_faixa_horario'\n",
      "2025-06-12 13:10:19,629 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:20,750 |     INFO | Successfully loaded 1862 rows using custom query\n",
      "2025-06-12 13:10:20,751 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-12 13:10:20,752 |     INFO | Replaced {posto_id} with 684\n",
      "2025-06-12 13:10:20,753 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-12 13:10:20,754 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-12 13:10:20,755 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscOrcamento.sql\n",
      "2025-06-12 13:10:20,756 |     INFO | Loading database data for entity 'df_orcamento'\n",
      "2025-06-12 13:10:20,757 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:32,890 |     INFO | Successfully loaded 21900 rows using custom query\n",
      "2025-06-12 13:10:32,894 |     INFO | df_orcamento columns: ['fk_unidade', 'unidade', 'fk_secao', 'secao', 'fk_tipo_posto', 'tipo_posto', 'percentual_posto', 'fc', 'data', 'hora_ini', 'itens', 'valor', 'tipo']\n",
      "2025-06-12 13:10:32,895 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-12 13:10:32,897 |     INFO | Replaced {start_date} with '2025-01-01'\n",
      "2025-06-12 13:10:32,897 |     INFO | Replaced {end_date} with '2025-12-31'\n",
      "2025-06-12 13:10:32,898 |     INFO | Replaced {posto_id} with 684\n",
      "2025-06-12 13:10:32,899 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetEscEstimado.sql\n",
      "2025-06-12 13:10:32,899 |     INFO | Loading database data for entity 'df_granularidade'\n",
      "2025-06-12 13:10:32,900 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:46,260 |     INFO | Successfully loaded 21287 rows using custom query\n",
      "   ‚úÖ Estimativas info loaded\n",
      "      üìà 0 estimate records\n",
      "2025-06-12 13:10:46,275 |     INFO | df_colaborador shape: (1, 47)\n",
      "2025-06-12 13:10:46,276 |     INFO | df_colaborador columns: ['fk_colaborador', 'loja', 'secao', 'puesto', 'convenio', 'nome', 'emp', 'min_dias_trabalhados', 'max_dias_trabalhados', 'tipo_de_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'lq', 'q', 'fds_cal_2d', 'fds_cal_3d', 'd_cal_xx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde']\n",
      "2025-06-12 13:10:46,281 |     INFO | Found 0 employees with 90-day cycles\n",
      "2025-06-12 13:10:46,283 |     INFO | first_date_passado: 2025-01-01\n",
      "2025-06-12 13:10:46,286 |     INFO | last_date_passado: 2026-01-07\n",
      "2025-06-12 13:10:46,293 |     INFO | Found 0 employees with past admission dates\n",
      "2025-06-12 13:10:46,297 |     INFO | No historical calendar data for employees: []\n",
      "2025-06-12 13:10:46,299 |     INFO | Loading query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-12 13:10:46,301 |     INFO | Replaced {colabs_id} with '5039619'\n",
      "2025-06-12 13:10:46,302 |     INFO | Loaded query from file: C:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\sql_querys\\queryGetAusencias.sql\n",
      "2025-06-12 13:10:46,303 |     INFO | Loading database data for entity 'df_ausencias_ferias'\n",
      "2025-06-12 13:10:46,304 |     INFO | Executing custom query\n",
      "2025-06-12 13:10:46,360 |     INFO | Successfully loaded 0 rows using custom query\n",
      "2025-06-12 13:10:46,362 |     INFO | No employees with 90-day cycles\n",
      "2025-06-12 13:10:46,365 |     INFO | load_calendario_info completed successfully\n",
      "   ‚úÖ Calendario info loaded\n",
      "      üìÖ Calendar matrix: (0, 0)\n",
      "\n",
      "üîÑ Stage 3: Performing data transformations...\n",
      "2025-06-12 13:10:46,399 |     INFO | df_feriados_filtered columns: ['fk_unidade', 'fk_pais', 'fk_estado', 'fk_cidade', 'database', 'descricao', 'tipo', 'feriado_fixo']\n",
      "   ‚úÖ Estimativas transformations completed\n",
      "2025-06-12 13:10:52,165 |     INFO | Starting load_ma_bd processing\n",
      "2025-06-12 13:10:52,192 |    ERROR | Empleado 5039619 sin suficiente LQ para fines de semana de calidad\n",
      "2025-06-12 13:10:52,193 |     INFO | columnes matriz a: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato']\n",
      "2025-06-12 13:10:52,197 |     INFO | load_ma_bd completed successfully. Processed 1 employees.\n",
      "   ‚úÖ Colaborador transformations completed\n",
      "2025-06-12 13:10:52,202 |     INFO | Starting load_m2_bd processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:864: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  output_final = output_final.fillna(0)\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1062: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matriz_ma[non_date_columns] = matriz_ma[non_date_columns].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:11:14,828 |     INFO | load_m2_bd completed successfully. Created calendar matrix with shape: (4, 731)\n",
      "2025-06-12 13:11:14,829 |     INFO | First few rows of created matrix:\n",
      "2025-06-12 13:11:14,836 |     INFO |           0           1           2           3           4           5    \\\n",
      "0         Dia  2025-01-01  2025-01-01  2025-01-02  2025-01-02  2025-01-03   \n",
      "1    TIPO_DIA           F           F           F           F           -   \n",
      "2       TURNO           M           T           M           T           M   \n",
      "3  0005039619           M           0           M           0           M   \n",
      "\n",
      "          6           7           8           9    ...         721  \\\n",
      "0  2025-01-03  2025-01-04  2025-01-04  2025-01-05  ...  2025-12-27   \n",
      "1           -           -           -           F  ...           -   \n",
      "2           T           M           T           M  ...           M   \n",
      "3           0           M           0           M  ...           0   \n",
      "\n",
      "          722         723         724         725         726         727  \\\n",
      "0  2025-12-27  2025-12-28  2025-12-28  2025-12-29  2025-12-29  2025-12-30   \n",
      "1           -           -           -           -           -           -   \n",
      "2           T           M           T           M           T           M   \n",
      "3           T           0           T           0           T           0   \n",
      "\n",
      "          728         729         730  \n",
      "0  2025-12-30  2025-12-31  2025-12-31  \n",
      "1           -           -           -  \n",
      "2           T           M           T  \n",
      "3           T           M           0  \n",
      "\n",
      "[4 rows x 731 columns]\n",
      "   ‚úÖ Calendario transformations completed\n",
      "2025-06-12 13:11:14,838 |     INFO | matriz2_og shape: (4, 731)\n",
      "2025-06-12 13:11:14,844 |     INFO | matriz2_og first few rows:\n",
      "          0           1           2           3           4           5    \\\n",
      "0         Dia  2025-01-01  2025-01-01  2025-01-02  2025-01-02  2025-01-03   \n",
      "1    TIPO_DIA           F           F           F           F           -   \n",
      "2       TURNO           M           T           M           T           M   \n",
      "3  0005039619           M           0           M           0           M   \n",
      "\n",
      "          6           7           8           9    ...         721  \\\n",
      "0  2025-01-03  2025-01-04  2025-01-04  2025-01-05  ...  2025-12-27   \n",
      "1           -           -           -           F  ...           -   \n",
      "2           T           M           T           M  ...           M   \n",
      "3           0           M           0           M  ...           0   \n",
      "\n",
      "          722         723         724         725         726         727  \\\n",
      "0  2025-12-27  2025-12-28  2025-12-28  2025-12-29  2025-12-29  2025-12-30   \n",
      "1           -           -           -           -           -           -   \n",
      "2           T           M           T           M           T           M   \n",
      "3           T           0           T           0           T           0   \n",
      "\n",
      "          728         729         730  \n",
      "0  2025-12-30  2025-12-31  2025-12-31  \n",
      "1           -           -           -  \n",
      "2           T           M           T  \n",
      "3           T           M           0  \n",
      "\n",
      "[4 rows x 731 columns]\n",
      "2025-06-12 13:11:14,845 |     INFO | matriz2_og first column unique values: ['Dia' 'TIPO_DIA' 'TURNO' '0005039619']\n",
      "2025-06-12 13:11:14,847 |     INFO | TURNO row exists: True\n",
      "2025-06-12 13:11:14,848 |     INFO | Dia row exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1547: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  matrizB_ini.loc[matrizB_ini['data'].isin(special_dates), 'min_turno'] = matrizB_ini['max_turno']\n",
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1548: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  mask_friday = (matrizB_ini['data'].isin(friday_dates)) & (matrizB_ini['turno'] == 'M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:11:15,089 |     INFO | Columns in matrizA_og after processing: ['fk_colaborador', 'unidade', 'secao', 'posto', 'convenio', 'nome', 'matricula', 'min_dia_trab', 'max_dia_trab', 'tipo_turno', 'seq_turno', 't_total', 'l_total', 'dyf_max_t', 'q', 'c2d', 'c3d', 'cxx', 'semana_1', 'out', 'ciclo', 'data_admissao', 'data_demissao', 'fk_tipo_posto', 'h_tm_in', 'h_tm_out', 'h_tt_in', 'h_tt_out', 'h_seg_in', 'h_seg_out', 'h_ter_in', 'h_ter_out', 'h_qua_in', 'h_qua_out', 'h_qui_in', 'h_qui_out', 'h_sex_in', 'h_sex_out', 'h_sab_in', 'h_sab_out', 'h_dom_in', 'h_dom_out', 'h_fer_in', 'h_fer_out', 'limite_superior_manha', 'limite_inferior_tarde', 'emp', 'lq', 'min', 'max', 'tipo_contrato', 'ld', 'l_dom', 'lq_og', 'total_dom_fes', 'total_fes', 'total_holidays', 'descansos_atrb', 'COLABORADOR', 'LD_at', 'LQ_at', 'LRES_at', 'CXX_at', 'C2D_at', 'C3D_at']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ALCAMPO\\python-algorithms\\algortimo-gd\\src\\models.py:1953: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matrizA_og = matrizA_og.merge(count_ldt, left_on='matricula', right_on='COLABORADOR', how='left').fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:11:16,313 |     INFO | func_inicializa MatrizB creation completed successfully\n",
      "2025-06-12 13:11:16,315 |     INFO | func_inicializa completed successfully\n",
      "   ‚úÖ func_inicializa completed\n",
      "2025-06-12 13:11:16,421 |     INFO | Closed database session\n",
      "2025-06-12 13:11:16,533 |     INFO | Disposed database engine\n",
      "\n",
      "üéâ Data loading completed!\n",
      "\n",
      "üìä Organizing DataFrames for interactive access...\n",
      "\n",
      "üìã AVAILABLE DATAFRAMES\n",
      "======================================================================\n",
      "\n",
      "üóÇÔ∏è AUXILIARY:\n",
      "   üìã messages_df               ‚Üí      0 rows √ó   0 columns\n",
      "   üìã params_lq                 ‚Üí      5 rows √ó   2 columns\n",
      "   üìã valid_emp                 ‚Üí      1 rows √ó   8 columns\n",
      "   üìã colabs_id_list            ‚Üí      1 rows √ó   0 columns\n",
      "   üìã df_festivos               ‚Üí     14 rows √ó   2 columns\n",
      "   üìã df_turnos                 ‚Üí      2 rows √ó   6 columns\n",
      "   üìã df_calendario_passado     ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_count                  ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_estrutura_wfm          ‚Üí   2777 rows √ó   6 columns\n",
      "   üìã df_feriados               ‚Üí   1743 rows √ó   8 columns\n",
      "   üìã df_faixa_horario          ‚Üí   1862 rows √ó  19 columns\n",
      "   üìã df_orcamento              ‚Üí  21900 rows √ó  13 columns\n",
      "   üìã df_granularidade          ‚Üí  21287 rows √ó  11 columns\n",
      "   üìã df_calendario_past        ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_ausencias_ferias       ‚Üí      0 rows √ó   0 columns\n",
      "   üìã df_ciclos_90              ‚Üí      0 rows √ó   0 columns\n",
      "\n",
      "üìÅ RAW:\n",
      "   üìã df_calendario             ‚Üí      4 rows √ó 731 columns\n",
      "   üìã df_colaborador            ‚Üí      1 rows √ó  54 columns\n",
      "   üìã df_estimativas            ‚Üí    730 rows √ó   8 columns\n",
      "\n",
      "‚öôÔ∏è MEDIUM (Transformed):\n",
      "   üìã matrizA_bk                ‚Üí      1 rows √ó  22 columns\n",
      "   üìã matriz2_bk                ‚Üí   1456 rows √ó  12 columns\n",
      "   üìã matrizB_bk                ‚Üí      0 rows √ó  13 columns\n",
      "   üìã matrizA                   ‚Üí      1 rows √ó  22 columns\n",
      "   üìã matrizA_bk_og             ‚Üí      1 rows √ó  21 columns\n",
      "   üìã matriz_data_turno_bk      ‚Üí      1 rows √ó   1 columns\n",
      "\n",
      "üíé RARE (Algorithm Results): (no DataFrames yet)\n",
      "\n",
      "üìä FORMATTED (Final): (no DataFrames yet)\n",
      "\n",
      "üîó QUICK ACCESS VARIABLES\n",
      "======================================================================\n",
      "‚úÖ valid_emp           ‚Üí (1, 8)\n",
      "‚úÖ df_colaborador      ‚Üí (1, 54)\n",
      "‚úÖ df_estimativas      ‚Üí (730, 8)\n",
      "‚úÖ df_calendario       ‚Üí (4, 731)\n",
      "‚úÖ matrizA_bk          ‚Üí (1, 22)\n",
      "‚úÖ matriz2_bk          ‚Üí (1456, 12)\n",
      "‚úÖ matrizB_bk          ‚Üí (0, 13)\n",
      "\n",
      "üõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\n",
      "======================================================================\n",
      "üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\n",
      "üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\n",
      "üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\n",
      "üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\n",
      "üìä df_info()                                  ‚Üí Show all DataFrames info\n",
      "\n",
      "üí° EXAMPLE USAGE:\n",
      "======================================================================\n",
      "# Explore specific DataFrames\n",
      "explore_df(valid_emp, 'Valid Employees')\n",
      "explore_df(df_colaborador, 'Employee Details')\n",
      "\n",
      "# Compare DataFrames\n",
      "compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\n",
      "\n",
      "# Show sample data\n",
      "show_sample_data(raw_dataframes, 'Raw Data', 3)\n",
      "\n",
      "# Search for specific columns\n",
      "search_columns('matricula')\n",
      "search_columns('data')\n",
      "\n",
      "# Access DataFrames directly\n",
      "valid_emp.head()\n",
      "df_colaborador.describe()\n",
      "matrizA_bk.columns\n",
      "\n",
      "üéØ DIRECT ACCESS TO PROJECT DATA:\n",
      "======================================================================\n",
      "üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\n",
      "üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\n",
      "‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\n",
      "üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\n",
      "üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\n",
      "\n",
      "üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\n",
      "üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\n",
      "‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\n",
      "\n",
      "‚ú® READY FOR INTERACTIVE DEVELOPMENT!\n",
      "üîß All project DataFrames are loaded and available in memory\n",
      "üìù Use the utility functions above to explore and analyze the data\n",
      "üöÄ Start developing your data transformations!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Development Notebook - Algoritmo GD Project\n",
    "# Load real project data and keep DataFrames in memory for development\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "# Add project root to path so we can import from src/\n",
    "project_root = Path.cwd()\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"üöÄ Interactive Development Environment - Algoritmo GD Project\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. IMPORT PROJECT MODULES AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Import project configuration and modules\n",
    "    from src.config import CONFIG, PROJECT_NAME\n",
    "    from src.models import DescansosDataModel\n",
    "    from base_data_project.utils import create_components\n",
    "    from base_data_project.log_config import setup_logger\n",
    "    \n",
    "    print(\"‚úÖ Project modules imported successfully\")\n",
    "    print(f\"üìÅ Project: {PROJECT_NAME}\")\n",
    "    print(f\"üóÇÔ∏è  Root directory: {project_root}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing project modules: {e}\")\n",
    "    print(\"Make sure you're running this notebook from the project root directory\")\n",
    "    raise\n",
    "\n",
    "# Configure logging\n",
    "logger = setup_logger(PROJECT_NAME, log_level=logging.INFO)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CONFIGURATION AND EXTERNAL DATA SETUP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã Setting up configuration and external data...\")\n",
    "\n",
    "# Use the real project configuration\n",
    "use_db = False  # Set to True if you want to use database, False for CSV\n",
    "external_call_data = CONFIG.get('external_call_data', {\n",
    "    'current_process_id': 249652,\n",
    "    'api_proc_id': 999,\n",
    "    'wfm_proc_id': 249652,\n",
    "    'wfm_user': 'WFM',\n",
    "    'start_date': '2025-01-01',\n",
    "    'end_date': '2025-12-31',\n",
    "    'wfm_proc_colab': None,\n",
    "})\n",
    "\n",
    "print(f\"üìä Data source: {'Database' if use_db else 'CSV files'}\")\n",
    "print(f\"üìÖ Date range: {external_call_data['start_date']} to {external_call_data['end_date']}\")\n",
    "print(f\"üî¢ Process ID: {external_call_data['current_process_id']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. INITIALIZE DATA MANAGER AND COMPONENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîß Initializing data manager and components...\")\n",
    "\n",
    "try:\n",
    "    # Create data manager using the project's utility function\n",
    "    data_manager, process_manager = create_components(\n",
    "        use_db=use_db, \n",
    "        no_tracking=True,  # Disable tracking for development\n",
    "        config=CONFIG\n",
    "    )\n",
    "    print(\"‚úÖ Data manager created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating data manager: {e}\")\n",
    "    raise\n",
    "\n",
    "# =============================================================================\n",
    "# 4. LOAD PROJECT DATA INTO MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Loading project data into memory...\")\n",
    "\n",
    "# Initialize the data model with real project structure\n",
    "data_model = DescansosDataModel(\n",
    "    project_name=PROJECT_NAME, \n",
    "    external_data=external_call_data\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data model initialized\")\n",
    "\n",
    "# Context manager for data manager connection\n",
    "with data_manager:\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.1 LOAD PROCESS DATA (Stage 1)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 1: Loading process data...\")\n",
    "    \n",
    "    try:\n",
    "        # Get entities to load from configuration\n",
    "        entities_dict = CONFIG.get('available_entities_processing', {})\n",
    "        \n",
    "        success = data_model.load_process_data(data_manager, entities_dict)\n",
    "        \n",
    "        if success:\n",
    "            print(\"‚úÖ Process data loaded successfully\")\n",
    "            print(f\"   üìã Valid employees: {len(data_model.auxiliary_data.get('valid_emp', []))} records\")\n",
    "            print(f\"   üè¢ Unit ID: {data_model.auxiliary_data.get('unit_id')}\")\n",
    "            print(f\"   üè≠ Section ID: {data_model.auxiliary_data.get('secao_id')}\")\n",
    "            print(f\"   üë§ Position IDs: {data_model.auxiliary_data.get('posto_id_list')}\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load process data\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Stage 1: {e}\")\n",
    "        logger.error(f\"Stage 1 error: {e}\", exc_info=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.2 LOAD DETAILED DATA FOR EACH POSITION (Stage 2)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 2: Loading detailed data for positions...\")\n",
    "    \n",
    "    posto_id_list = data_model.auxiliary_data.get('posto_id_list', [])\n",
    "    \n",
    "    if posto_id_list:\n",
    "        # Process first position as example (you can modify this)\n",
    "        posto_id = posto_id_list[0]\n",
    "        print(f\"üìç Processing position ID: {posto_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load colaborador info\n",
    "            success = data_model.load_colaborador_info(data_manager, posto_id)\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Colaborador info loaded\")\n",
    "                df_colaborador = data_model.raw_data.get('df_colaborador')\n",
    "                if df_colaborador is not None:\n",
    "                    print(f\"      üìä {len(df_colaborador)} employee records\")\n",
    "            \n",
    "            # Load estimativas info  \n",
    "            success = data_model.load_estimativas_info(\n",
    "                data_manager, \n",
    "                posto_id, \n",
    "                external_call_data['start_date'], \n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Estimativas info loaded\")\n",
    "                df_estimativas = data_model.raw_data.get('df_estimativas')\n",
    "                if df_estimativas is not None:\n",
    "                    print(f\"      üìà {len(df_estimativas)} estimate records\")\n",
    "            \n",
    "            # Load calendario info\n",
    "            success = data_model.load_calendario_info(\n",
    "                data_manager,\n",
    "                external_call_data['current_process_id'],\n",
    "                posto_id,\n",
    "                external_call_data['start_date'],\n",
    "                external_call_data['end_date']\n",
    "            )\n",
    "            if success:\n",
    "                print(f\"   ‚úÖ Calendario info loaded\")\n",
    "                df_calendario = data_model.raw_data.get('df_calendario')\n",
    "                if df_calendario is not None:\n",
    "                    print(f\"      üìÖ Calendar matrix: {df_calendario.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error loading data for position {posto_id}: {e}\")\n",
    "            logger.error(f\"Position {posto_id} error: {e}\", exc_info=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4.3 PERFORM DATA TRANSFORMATIONS (Stage 3)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\nüîÑ Stage 3: Performing data transformations...\")\n",
    "    \n",
    "    try:\n",
    "        # Load estimativas transformations\n",
    "        success = data_model.load_estimativas_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Estimativas transformations completed\")\n",
    "        \n",
    "        # Load colaborador transformations  \n",
    "        success = data_model.load_colaborador_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Colaborador transformations completed\")\n",
    "        \n",
    "        # Load calendario transformations\n",
    "        success = data_model.load_calendario_transformations()\n",
    "        if success:\n",
    "            print(\"   ‚úÖ Calendario transformations completed\")\n",
    "        \n",
    "        # Perform func_inicializa\n",
    "        success = data_model.func_inicializa(\n",
    "            start_date=external_call_data['start_date'],\n",
    "            end_date=external_call_data['end_date'],\n",
    "            fer=data_model.auxiliary_data.get('df_festivos'),\n",
    "            closed_days=data_model.auxiliary_data.get('df_closed_days')\n",
    "        )\n",
    "        if success:\n",
    "            print(\"   ‚úÖ func_inicializa completed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error in transformations: {e}\")\n",
    "        logger.error(f\"Transformation error: {e}\", exc_info=True)\n",
    "\n",
    "print(\"\\nüéâ Data loading completed!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ORGANIZE DATAFRAMES FOR EASY ACCESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Organizing DataFrames for interactive access...\")\n",
    "\n",
    "# Extract all DataFrames from the data model\n",
    "auxiliary_dataframes = {}\n",
    "raw_dataframes = {}\n",
    "medium_dataframes = {}\n",
    "rare_dataframes = {}\n",
    "formatted_dataframes = {}\n",
    "\n",
    "# Auxiliary data\n",
    "for key, value in data_model.auxiliary_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        auxiliary_dataframes[key] = value\n",
    "\n",
    "# Raw data  \n",
    "for key, value in data_model.raw_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        raw_dataframes[key] = value\n",
    "\n",
    "# Medium data (transformed)\n",
    "for key, value in data_model.medium_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        medium_dataframes[key] = value\n",
    "\n",
    "# Rare data (algorithm results)\n",
    "for key, value in data_model.rare_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        rare_dataframes[key] = value\n",
    "\n",
    "# Formatted data (final output)\n",
    "for key, value in data_model.formatted_data.items():\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        formatted_dataframes[key] = value\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DISPLAY AVAILABLE DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã AVAILABLE DATAFRAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_dataframes = {\n",
    "    \"üóÇÔ∏è AUXILIARY\": auxiliary_dataframes,\n",
    "    \"üìÅ RAW\": raw_dataframes, \n",
    "    \"‚öôÔ∏è MEDIUM (Transformed)\": medium_dataframes,\n",
    "    \"üíé RARE (Algorithm Results)\": rare_dataframes,\n",
    "    \"üìä FORMATTED (Final)\": formatted_dataframes\n",
    "}\n",
    "\n",
    "for category, dataframes in all_dataframes.items():\n",
    "    if dataframes:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, df in dataframes.items():\n",
    "            print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: (no DataFrames yet)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. QUICK ACCESS VARIABLES AND UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîó QUICK ACCESS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make key DataFrames easily accessible with simple variable names\n",
    "try:\n",
    "    if 'valid_emp' in auxiliary_dataframes:\n",
    "        valid_emp = auxiliary_dataframes['valid_emp']\n",
    "        print(f\"‚úÖ valid_emp           ‚Üí {valid_emp.shape}\")\n",
    "    \n",
    "    if 'df_colaborador' in raw_dataframes:\n",
    "        df_colaborador = raw_dataframes['df_colaborador']\n",
    "        print(f\"‚úÖ df_colaborador      ‚Üí {df_colaborador.shape}\")\n",
    "    \n",
    "    if 'df_estimativas' in raw_dataframes:\n",
    "        df_estimativas = raw_dataframes['df_estimativas']\n",
    "        print(f\"‚úÖ df_estimativas      ‚Üí {df_estimativas.shape}\")\n",
    "    \n",
    "    if 'df_calendario' in raw_dataframes:\n",
    "        df_calendario = raw_dataframes['df_calendario']\n",
    "        print(f\"‚úÖ df_calendario       ‚Üí {df_calendario.shape}\")\n",
    "    \n",
    "    if 'matrizA_bk' in medium_dataframes:\n",
    "        matrizA_bk = medium_dataframes['matrizA_bk']\n",
    "        print(f\"‚úÖ matrizA_bk          ‚Üí {matrizA_bk.shape}\")\n",
    "    \n",
    "    if 'matriz2_bk' in medium_dataframes:\n",
    "        matriz2_bk = medium_dataframes['matriz2_bk']\n",
    "        print(f\"‚úÖ matriz2_bk          ‚Üí {matriz2_bk.shape}\")\n",
    "    \n",
    "    if 'matrizB_bk' in medium_dataframes:\n",
    "        matrizB_bk = medium_dataframes['matrizB_bk']\n",
    "        print(f\"‚úÖ matrizB_bk          ‚Üí {matrizB_bk.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some DataFrames may not be available yet: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. UTILITY FUNCTIONS FOR DATA EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def explore_df(df, name=\"DataFrame\"):\n",
    "    \"\"\"Explore a DataFrame with detailed information\"\"\"\n",
    "    print(f\"\\nüîç EXPLORING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìè Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nüìã Columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        print(f\"   {i+1:2d}. {col:<20} ({dtype}) - {null_count} nulls\")\n",
    "    \n",
    "    print(f\"\\nüìä First 3 rows:\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_dfs(*dataframes, names=None):\n",
    "    \"\"\"Compare multiple DataFrames\"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"DataFrame_{i+1}\" for i in range(len(dataframes))]\n",
    "    \n",
    "    print(f\"\\nüîÑ COMPARING DATAFRAMES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in zip(names, dataframes):\n",
    "        print(f\"üìã {name:<20} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} columns\")\n",
    "    \n",
    "    # Check for common columns\n",
    "    if len(dataframes) > 1:\n",
    "        all_columns = [set(df.columns) for df in dataframes]\n",
    "        common_cols = set.intersection(*all_columns)\n",
    "        \n",
    "        print(f\"\\nüîó Common columns ({len(common_cols)}):\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "def show_sample_data(df_dict, category_name, n_rows=3):\n",
    "    \"\"\"Show sample data from DataFrames in a category\"\"\"\n",
    "    print(f\"\\nüìñ SAMPLE DATA: {category_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"\\nüîπ {name} (showing {min(n_rows, len(df))} rows):\")\n",
    "        if len(df) > 0:\n",
    "            print(df.head(n_rows).to_string())\n",
    "        else:\n",
    "            print(\"   (empty DataFrame)\")\n",
    "\n",
    "def search_columns(pattern, df_dict=None):\n",
    "    \"\"\"Search for columns matching a pattern across all DataFrames\"\"\"\n",
    "    if df_dict is None:\n",
    "        df_dict = {**auxiliary_dataframes, **raw_dataframes, **medium_dataframes}\n",
    "    \n",
    "    print(f\"\\nüîç SEARCHING COLUMNS: '{pattern}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found = False\n",
    "    for df_name, df in df_dict.items():\n",
    "        matching_cols = [col for col in df.columns if pattern.lower() in col.lower()]\n",
    "        if matching_cols:\n",
    "            found = True\n",
    "            print(f\"\\nüìã {df_name}:\")\n",
    "            for col in matching_cols:\n",
    "                print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"‚ùå No columns found matching '{pattern}'\")\n",
    "\n",
    "def df_info():\n",
    "    \"\"\"Show information about all available DataFrames\"\"\"\n",
    "    print(f\"\\nüìä ALL DATAFRAMES INFO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    categories = [\n",
    "        (\"üóÇÔ∏è AUXILIARY\", auxiliary_dataframes),\n",
    "        (\"üìÅ RAW\", raw_dataframes),\n",
    "        (\"‚öôÔ∏è MEDIUM\", medium_dataframes),\n",
    "        (\"üíé RARE\", rare_dataframes),\n",
    "        (\"üìä FORMATTED\", formatted_dataframes)\n",
    "    ]\n",
    "    \n",
    "    for category_name, df_dict in categories:\n",
    "        if df_dict:\n",
    "            print(f\"\\n{category_name}:\")\n",
    "            for name, df in df_dict.items():\n",
    "                memory_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "                print(f\"   üìã {name:<25} ‚Üí {df.shape[0]:>6} rows √ó {df.shape[1]:>3} cols ({memory_mb:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. INSTRUCTIONS AND EXAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è UTILITY FUNCTIONS AVAILABLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç explore_df(dataframe, 'name')              ‚Üí Detailed DataFrame exploration\")\n",
    "print(\"üîÑ compare_dfs(df1, df2, names=['A', 'B'])    ‚Üí Compare multiple DataFrames\")  \n",
    "print(\"üìñ show_sample_data(df_dict, 'category', 5)   ‚Üí Show sample data from category\")\n",
    "print(\"üîç search_columns('pattern')                  ‚Üí Find columns matching pattern\")\n",
    "print(\"üìä df_info()                                  ‚Üí Show all DataFrames info\")\n",
    "\n",
    "print(f\"\\nüí° EXAMPLE USAGE:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"# Explore specific DataFrames\")\n",
    "print(\"explore_df(valid_emp, 'Valid Employees')\")\n",
    "print(\"explore_df(df_colaborador, 'Employee Details')\")\n",
    "print(\"\")\n",
    "print(\"# Compare DataFrames\")\n",
    "print(\"compare_dfs(df_colaborador, matrizA_bk, names=['Raw', 'Processed'])\")\n",
    "print(\"\")\n",
    "print(\"# Show sample data\")\n",
    "print(\"show_sample_data(raw_dataframes, 'Raw Data', 3)\")\n",
    "print(\"\")\n",
    "print(\"# Search for specific columns\")\n",
    "print(\"search_columns('matricula')\")\n",
    "print(\"search_columns('data')\")\n",
    "print(\"\")\n",
    "print(\"# Access DataFrames directly\")\n",
    "print(\"valid_emp.head()\")\n",
    "print(\"df_colaborador.describe()\")\n",
    "print(\"matrizA_bk.columns\")\n",
    "\n",
    "print(f\"\\nüéØ DIRECT ACCESS TO PROJECT DATA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä data_model.auxiliary_data    ‚Üí Dictionary with auxiliary data\")\n",
    "print(\"üìÅ data_model.raw_data          ‚Üí Dictionary with raw DataFrames\")  \n",
    "print(\"‚öôÔ∏è data_model.medium_data       ‚Üí Dictionary with transformed DataFrames\")\n",
    "print(\"üíé data_model.rare_data         ‚Üí Dictionary with algorithm results\")\n",
    "print(\"üìã data_model.formatted_data    ‚Üí Dictionary with final formatted data\")\n",
    "print(\"\")\n",
    "print(\"üìä auxiliary_dataframes         ‚Üí Easy access to auxiliary DataFrames\")\n",
    "print(\"üìÅ raw_dataframes              ‚Üí Easy access to raw DataFrames\")\n",
    "print(\"‚öôÔ∏è medium_dataframes           ‚Üí Easy access to medium DataFrames\")\n",
    "\n",
    "print(f\"\\n‚ú® READY FOR INTERACTIVE DEVELOPMENT!\")\n",
    "print(\"üîß All project DataFrames are loaded and available in memory\")\n",
    "print(\"üìù Use the utility functions above to explore and analyze the data\")\n",
    "print(\"üöÄ Start developing your data transformations!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
